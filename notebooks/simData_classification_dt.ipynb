{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from impt_functions import *\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from fairlearn.reductions import ExponentiatedGradient, GridSearch, DemographicParity, EqualizedOdds, \\\n",
    "    TruePositiveRateParity, FalsePositiveRateParity, ErrorRateParity, BoundedGroupLoss\n",
    "from fairlearn.metrics import *\n",
    "from raiwidgets import FairnessDashboard\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       score  repay_probability  race  repay_indices\n",
      "0        601              75.21     1              1\n",
      "1        693              95.15     1              1\n",
      "2        791              98.62     1              1\n",
      "3        637              86.69     1              1\n",
      "4        775              98.45     1              1\n",
      "...      ...                ...   ...            ...\n",
      "99995    797              98.73     1              1\n",
      "99996    562              58.57     1              1\n",
      "99997    687              94.60     1              1\n",
      "99998    589              70.61     1              1\n",
      "99999    555              52.97     1              0\n",
      "\n",
      "[100000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "data = get_data('/home/mackenzie/git_repositories/delayedimpact/data/simData_oom100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the x values:  [[601   1]\n",
      " [693   1]\n",
      " [791   1]\n",
      " ...\n",
      " [687   1]\n",
      " [589   1]\n",
      " [555   1]] \n",
      "\n",
      "Here are the y values:  [1 1 1 ... 1 1 0]\n",
      "Sample weights are all equal.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, race_train, race_test, sample_weight_train, sample_weight_test = prep_data(data=data, test_size=0.3, weight_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train DTC classifier + Collect Predictions\n",
    "NOTE: atm sample_weight are all 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://www.datacamp.com/community/tutorials/decision-tree-classification-python\n",
    "\n",
    "# Initialize classifier:\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train the classifier:\n",
    "model = clf.fit(X_train,y_train)\n",
    "\n",
    "# Make predictions with the classifier:\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "# Scores on test set\n",
    "test_scores = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of classifier overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unmitigated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Overall selection rate</th>\n",
       "      <td>0.729567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demographic parity difference</th>\n",
       "      <td>0.450625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demographic parity ratio</th>\n",
       "      <td>0.424364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>------</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall balanced error rate</th>\n",
       "      <td>0.151732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced error rate difference</th>\n",
       "      <td>0.0170221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>------</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True positive rate difference</th>\n",
       "      <td>0.190934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True negative rate difference</th>\n",
       "      <td>0.156889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False positive rate difference</th>\n",
       "      <td>0.156889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False negative rate difference</th>\n",
       "      <td>0.190934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equalized odds difference</th>\n",
       "      <td>0.190934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>------</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall AUC</th>\n",
       "      <td>0.933059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC difference</th>\n",
       "      <td>0.0352201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Unmitigated\n",
       "Overall selection rate            0.729567\n",
       "Demographic parity difference     0.450625\n",
       "Demographic parity ratio          0.424364\n",
       "------                                    \n",
       "Overall balanced error rate       0.151732\n",
       "Balanced error rate difference   0.0170221\n",
       " ------                                   \n",
       "True positive rate difference     0.190934\n",
       "True negative rate difference     0.156889\n",
       "False positive rate difference    0.156889\n",
       "False negative rate difference    0.190934\n",
       "Equalized odds difference         0.190934\n",
       "  ------                                  \n",
       "Overall AUC                       0.933059\n",
       "AUC difference                   0.0352201"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metrics\n",
    "models_dict = {\"Unmitigated\": (y_predict, test_scores)}\n",
    "get_metrics_df(models_dict, y_test, race_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6644  2036]\n",
      " [ 1469 19851]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.77      0.79      8680\n",
      "           1       0.91      0.93      0.92     21320\n",
      "\n",
      "    accuracy                           0.88     30000\n",
      "   macro avg       0.86      0.85      0.86     30000\n",
      "weighted avg       0.88      0.88      0.88     30000\n",
      "\n",
      "TNR=TN/(TN+FP)=  0.7654377880184332\n",
      "TPR=TP/(FP+FN)=  0.9310975609756098\n",
      "FNER=FN/(FN+TP)=  0.06890243902439025\n",
      "FPER=FP/(FP+TN)=  0.23456221198156682\n",
      "F1 score micro: \n",
      "0.8831666666666667\n",
      "F1 score weighted: \n",
      "0.8819608768731572\n",
      "F1 score binary: \n",
      "0.9188788853657973\n",
      "Selection Rate Overall:  0.7295666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The positional argument 'metric' has been replaced by a keyword argument 'metrics'. From version 0.10.0 passing it as a positional argument or as a keyword argument 'metric' will result in an error\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_predict)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_predict)) \n",
    "evaluation_outcome_rates(y_test, y_predict, sample_weight_test)\n",
    "get_f1_scores(y_test, y_predict)\n",
    "get_selection_rates(y_test, y_predict, race_test, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of classifier by race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection Rate By Group:  sensitive_feature_0\n",
      "0    0.332205\n",
      "1    0.782831\n",
      "Name: selection_rate, dtype: object \n",
      "\n",
      "EVALUATION FOR BLACK GROUP\n",
      "[[2071  283]\n",
      " [ 297  895]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88      2354\n",
      "           1       0.76      0.75      0.76      1192\n",
      "\n",
      "    accuracy                           0.84      3546\n",
      "   macro avg       0.82      0.82      0.82      3546\n",
      "weighted avg       0.84      0.84      0.84      3546\n",
      "\n",
      "TNR=TN/(TN+FP)=  0.8797790994052677\n",
      "TPR=TP/(FP+FN)=  0.7508389261744967\n",
      "FNER=FN/(FN+TP)=  0.24916107382550334\n",
      "FPER=FP/(FP+TN)=  0.12022090059473237\n",
      "F1 score micro: \n",
      "0.8364354201917654\n",
      "F1 score weighted: \n",
      "0.8361947899037017\n",
      "F1 score binary: \n",
      "0.7552742616033755\n",
      "\n",
      "EVALUATION FOR WHITE GROUP\n",
      "[[ 4573  1753]\n",
      " [ 1172 18956]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      6326\n",
      "           1       0.92      0.94      0.93     20128\n",
      "\n",
      "    accuracy                           0.89     26454\n",
      "   macro avg       0.86      0.83      0.84     26454\n",
      "weighted avg       0.89      0.89      0.89     26454\n",
      "\n",
      "TNR=TN/(TN+FP)=  0.7228896617135631\n",
      "TPR=TP/(FP+FN)=  0.9417726550079492\n",
      "FNER=FN/(FN+TP)=  0.05822734499205087\n",
      "FPER=FP/(FP+TN)=  0.27711033828643694\n",
      "F1 score micro: \n",
      "0.8894307099115446\n",
      "F1 score weighted: \n",
      "0.8875563065518303\n",
      "F1 score binary: \n",
      "0.928373778681098\n"
     ]
    }
   ],
   "source": [
    "evaluation_by_race(X_test, y_test, race_test, y_predict, sample_weight_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delayed impact calculated by race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The delayed impact of the black group is:  6.958544839255499\n",
      "The delayed impact of the white group is:  43.80244953504196\n"
     ]
    }
   ],
   "source": [
    "calculate_delayed_impact(X_test, y_test, y_predict, race_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Metric Evaluation of classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP Difference:  0.45062527207781544\n",
      "-->difference of 0 means that all groups have the same selection rate\n",
      "DP Ratio: 0.42436424030390024\n",
      "-->ratio of 1 means that all groups have the same selection rate \n",
      "\n",
      "EOD Difference:  0.1909337288334525\n",
      "-->difference of 0 means that all groups have the same TN, TN, FP, and FN rates\n",
      "EOD Ratio: 0.4338376595335293\n",
      "-->ratio of 1 means that all groups have the same TN, TN, FP, and FN rates rates \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_fairness_metrics(y_test, y_predict, race_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponentiated Gradient Reduction Alg for Adding Fairness Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographic Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exponentiated Gradient Reduction Alg is used here with  DP  as the fairness constraint.\n",
      "\n",
      "Evaluation of  DP -constrained classifier overall:\n",
      "[[ 5473  3207]\n",
      " [ 1272 20048]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.63      0.71      8680\n",
      "           1       0.86      0.94      0.90     21320\n",
      "\n",
      "    accuracy                           0.85     30000\n",
      "   macro avg       0.84      0.79      0.80     30000\n",
      "weighted avg       0.85      0.85      0.84     30000\n",
      "\n",
      "TNR=TN/(TN+FP)=  0.6305299539170507\n",
      "TPR=TP/(FP+FN)=  0.9403377110694184\n",
      "FNER=FN/(FN+TP)=  0.05966228893058161\n",
      "FPER=FP/(FP+TN)=  0.3694700460829493\n",
      "F1 score micro: \n",
      "0.8507000000000001\n",
      "F1 score weighted: \n",
      "0.8445760333639062\n",
      "F1 score binary: \n",
      "0.8995176668536176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The positional argument 'metric' has been replaced by a keyword argument 'metrics'. From version 0.10.0 passing it as a positional argument or as a keyword argument 'metric' will result in an error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection Rate Overall:  0.7751666666666667\n",
      "\n",
      "\n",
      "Evaluation of  DP -constrained classifier by race:\n",
      "Selection Rate By Group:  sensitive_feature_0\n",
      "0    0.759729\n",
      "1    0.777236\n",
      "Name: selection_rate, dtype: object \n",
      "\n",
      "EVALUATION FOR BLACK GROUP\n",
      "[[ 822 1532]\n",
      " [  30 1162]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.35      0.51      2354\n",
      "           1       0.43      0.97      0.60      1192\n",
      "\n",
      "    accuracy                           0.56      3546\n",
      "   macro avg       0.70      0.66      0.56      3546\n",
      "weighted avg       0.79      0.56      0.54      3546\n",
      "\n",
      "TNR=TN/(TN+FP)=  0.3491928632115548\n",
      "TPR=TP/(FP+FN)=  0.9748322147651006\n",
      "FNER=FN/(FN+TP)=  0.025167785234899327\n",
      "FPER=FP/(FP+TN)=  0.6508071367884452\n",
      "F1 score micro: \n",
      "0.5595036661026509\n",
      "F1 score weighted: \n",
      "0.541447529417134\n",
      "F1 score binary: \n",
      "0.5980442614513639\n",
      "\n",
      "EVALUATION FOR WHITE GROUP\n",
      "[[ 4651  1675]\n",
      " [ 1242 18886]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      6326\n",
      "           1       0.92      0.94      0.93     20128\n",
      "\n",
      "    accuracy                           0.89     26454\n",
      "   macro avg       0.85      0.84      0.84     26454\n",
      "weighted avg       0.89      0.89      0.89     26454\n",
      "\n",
      "TNR=TN/(TN+FP)=  0.7352197281062283\n",
      "TPR=TP/(FP+FN)=  0.9382949125596184\n",
      "FNER=FN/(FN+TP)=  0.061705087440381556\n",
      "FPER=FP/(FP+TN)=  0.26478027189377173\n",
      "F1 score micro: \n",
      "0.8897331216451199\n",
      "F1 score weighted: \n",
      "0.888366092523213\n",
      "F1 score binary: \n",
      "0.9283098626164319\n",
      "\n",
      "\n",
      "Fairness metric evaluation of  DP -constrained classifier\n",
      "DP Difference:  0.017506684335494405\n",
      "-->difference of 0 means that all groups have the same selection rate\n",
      "DP Ratio: 0.977475714828502\n",
      "-->ratio of 1 means that all groups have the same selection rate \n",
      "\n",
      "EOD Difference:  0.3860268648946734\n",
      "-->difference of 0 means that all groups have the same TN, TN, FP, and FN rates\n",
      "EOD Ratio: 0.4068490600769835\n",
      "-->ratio of 1 means that all groups have the same TN, TN, FP, and FN rates rates \n",
      "\n",
      "The delayed impact of the black group is:  -40.22842639593909\n",
      "The delayed impact of the white group is:  44.046268995237014\n"
     ]
    }
   ],
   "source": [
    "eg_dp = add_contraint(model, 'DP', 'EG', X_train, y_train, race_train, race_test, X_test, y_test, y_predict, sample_weight_test, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equalized Odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exponentiated Gradient Reduction Alg is used here with  EO  as the fairness constraint.\n",
      "\n",
      "Evaluation of  EO -constrained classifier overall:\n",
      "[[ 6561  2119]\n",
      " [ 2192 19128]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75      8680\n",
      "           1       0.90      0.90      0.90     21320\n",
      "\n",
      "    accuracy                           0.86     30000\n",
      "   macro avg       0.82      0.83      0.83     30000\n",
      "weighted avg       0.86      0.86      0.86     30000\n",
      "\n",
      "TNR=TN/(TN+FP)=  0.7558755760368664\n",
      "TPR=TP/(FP+FN)=  0.8971857410881802\n",
      "FNER=FN/(FN+TP)=  0.10281425891181989\n",
      "FPER=FP/(FP+TN)=  0.24412442396313364\n",
      "F1 score micro: \n",
      "0.8563\n",
      "F1 score weighted: \n",
      "0.8564776503509381\n",
      "F1 score binary: \n",
      "0.8987243639439002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The positional argument 'metric' has been replaced by a keyword argument 'metrics'. From version 0.10.0 passing it as a positional argument or as a keyword argument 'metric' will result in an error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection Rate Overall:  0.7082333333333334\n",
      "\n",
      "\n",
      "Evaluation of  EO -constrained classifier by race:\n",
      "Selection Rate By Group:  sensitive_feature_0\n",
      "0    0.466441\n",
      "1    0.740644\n",
      "Name: selection_rate, dtype: object \n",
      "\n",
      "EVALUATION FOR BLACK GROUP\n",
      "[[1748  606]\n",
      " [ 144 1048]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.74      0.82      2354\n",
      "           1       0.63      0.88      0.74      1192\n",
      "\n",
      "    accuracy                           0.79      3546\n",
      "   macro avg       0.78      0.81      0.78      3546\n",
      "weighted avg       0.83      0.79      0.79      3546\n",
      "\n",
      "TNR=TN/(TN+FP)=  0.7425658453695837\n",
      "TPR=TP/(FP+FN)=  0.8791946308724832\n",
      "FNER=FN/(FN+TP)=  0.12080536912751678\n",
      "FPER=FP/(FP+TN)=  0.2574341546304163\n",
      "F1 score micro: \n",
      "0.7884940778341794\n",
      "F1 score weighted: \n",
      "0.7941544848700293\n",
      "F1 score binary: \n",
      "0.7364722417427969\n",
      "\n",
      "EVALUATION FOR WHITE GROUP\n",
      "[[ 4813  1513]\n",
      " [ 2048 18080]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.76      0.73      6326\n",
      "           1       0.92      0.90      0.91     20128\n",
      "\n",
      "    accuracy                           0.87     26454\n",
      "   macro avg       0.81      0.83      0.82     26454\n",
      "weighted avg       0.87      0.87      0.87     26454\n",
      "\n",
      "TNR=TN/(TN+FP)=  0.7608283275371482\n",
      "TPR=TP/(FP+FN)=  0.8982511923688394\n",
      "FNER=FN/(FN+TP)=  0.10174880763116058\n",
      "FPER=FP/(FP+TN)=  0.23917167246285173\n",
      "F1 score micro: \n",
      "0.8653889770923112\n",
      "F1 score weighted: \n",
      "0.867213044804007\n",
      "F1 score binary: \n",
      "0.9103496890813424\n",
      "\n",
      "\n",
      "Fairness metric evaluation of  EO -constrained classifier\n",
      "DP Difference:  0.2742030766428255\n",
      "-->difference of 0 means that all groups have the same selection rate\n",
      "DP Ratio: 0.6297775639509362\n",
      "-->ratio of 1 means that all groups have the same selection rate \n",
      "\n",
      "EOD Difference:  0.01905656149635626\n",
      "-->difference of 0 means that all groups have the same TN, TN, FP, and FN rates\n",
      "EOD Ratio: 0.9290595989728597\n",
      "-->ratio of 1 means that all groups have the same TN, TN, FP, and FN rates rates \n",
      "\n",
      "The delayed impact of the black group is:  -3.4686971235194584\n",
      "The delayed impact of the white group is:  42.6797459741438\n"
     ]
    }
   ],
   "source": [
    "eg_eo = add_contraint(model, 'EO', 'EG', X_train, y_train, race_train, race_test, X_test, y_test, y_predict, sample_weight_test, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EOO (True Positive Rate Parity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exponentiated Gradient Reduction Alg is used here with  TPRP  as the fairness constraint.\n",
      "\n",
      "Evaluation of  TPRP -constrained classifier overall:\n",
      "[[ 6216  2464]\n",
      " [ 1448 19872]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      8680\n",
      "           1       0.89      0.93      0.91     21320\n",
      "\n",
      "    accuracy                           0.87     30000\n",
      "   macro avg       0.85      0.82      0.84     30000\n",
      "weighted avg       0.87      0.87      0.87     30000\n",
      "\n",
      "TNR=TN/(TN+FP)=  0.7161290322580646\n",
      "TPR=TP/(FP+FN)=  0.9320825515947467\n",
      "FNER=FN/(FN+TP)=  0.06791744840525328\n",
      "FPER=FP/(FP+TN)=  0.2838709677419355\n",
      "F1 score micro: \n",
      "0.8695999999999999\n",
      "F1 score weighted: \n",
      "0.8670643312809774\n",
      "F1 score binary: \n",
      "0.9103903243540407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The positional argument 'metric' has been replaced by a keyword argument 'metrics'. From version 0.10.0 passing it as a positional argument or as a keyword argument 'metric' will result in an error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection Rate Overall:  0.7445333333333334\n",
      "\n",
      "\n",
      "Evaluation of  TPRP -constrained classifier by race:\n",
      "Selection Rate By Group:  sensitive_feature_0\n",
      "0    0.547095\n",
      "1    0.770999\n",
      "Name: selection_rate, dtype: object \n",
      "\n",
      "EVALUATION FOR BLACK GROUP\n",
      "[[1496  858]\n",
      " [ 110 1082]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.64      0.76      2354\n",
      "           1       0.56      0.91      0.69      1192\n",
      "\n",
      "    accuracy                           0.73      3546\n",
      "   macro avg       0.74      0.77      0.72      3546\n",
      "weighted avg       0.81      0.73      0.73      3546\n",
      "\n",
      "TNR=TN/(TN+FP)=  0.6355140186915887\n",
      "TPR=TP/(FP+FN)=  0.9077181208053692\n",
      "FNER=FN/(FN+TP)=  0.09228187919463088\n",
      "FPER=FP/(FP+TN)=  0.3644859813084112\n",
      "F1 score micro: \n",
      "0.7270163564579808\n",
      "F1 score weighted: \n",
      "0.7338322315936725\n",
      "F1 score binary: \n",
      "0.6909323116219669\n",
      "\n",
      "EVALUATION FOR WHITE GROUP\n",
      "[[ 4720  1606]\n",
      " [ 1338 18790]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76      6326\n",
      "           1       0.92      0.93      0.93     20128\n",
      "\n",
      "    accuracy                           0.89     26454\n",
      "   macro avg       0.85      0.84      0.84     26454\n",
      "weighted avg       0.89      0.89      0.89     26454\n",
      "\n",
      "TNR=TN/(TN+FP)=  0.746127094530509\n",
      "TPR=TP/(FP+FN)=  0.9335254372019078\n",
      "FNER=FN/(FN+TP)=  0.0664745627980922\n",
      "FPER=FP/(FP+TN)=  0.253872905469491\n",
      "F1 score micro: \n",
      "0.8887124820443033\n",
      "F1 score weighted: \n",
      "0.8878762975732954\n",
      "F1 score binary: \n",
      "0.9273516928240055\n",
      "\n",
      "\n",
      "Fairness metric evaluation of  TPRP -constrained classifier\n",
      "DP Difference:  0.22390339608120957\n",
      "-->difference of 0 means that all groups have the same selection rate\n",
      "DP Ratio: 0.7095930358927085\n",
      "-->ratio of 1 means that all groups have the same selection rate \n",
      "\n",
      "EOD Difference:  0.11061307583892022\n",
      "-->difference of 0 means that all groups have the same TN, TN, FP, and FN rates\n",
      "EOD Ratio: 0.696523099621424\n",
      "-->ratio of 1 means that all groups have the same TN, TN, FP, and FN rates rates \n",
      "\n",
      "The delayed impact of the black group is:  -13.40947546531303\n",
      "The delayed impact of the white group is:  44.165343615332276\n"
     ]
    }
   ],
   "source": [
    "eg_tprp = add_contraint(model, 'TPRP', 'EG', X_train, y_train, race_train, race_test, X_test, y_test, y_predict, sample_weight_test, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Positive Rate Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exponentiated Gradient Reduction Alg is used here with  FPRP  as the fairness constraint.\n",
      "\n",
      "Evaluation of  FPRP -constrained classifier overall:\n",
      "[[ 6393  2287]\n",
      " [ 1388 19932]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.74      0.78      8680\n",
      "           1       0.90      0.93      0.92     21320\n",
      "\n",
      "    accuracy                           0.88     30000\n",
      "   macro avg       0.86      0.84      0.85     30000\n",
      "weighted avg       0.88      0.88      0.88     30000\n",
      "\n",
      "TNR=TN/(TN+FP)=  0.7365207373271889\n",
      "TPR=TP/(FP+FN)=  0.9348968105065666\n",
      "FNER=FN/(FN+TP)=  0.0651031894934334\n",
      "FPER=FP/(FP+TN)=  0.2634792626728111\n",
      "F1 score micro: \n",
      "0.8775\n",
      "F1 score weighted: \n",
      "0.8754195958866932\n",
      "F1 score binary: \n",
      "0.9155929166953766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The positional argument 'metric' has been replaced by a keyword argument 'metrics'. From version 0.10.0 passing it as a positional argument or as a keyword argument 'metric' will result in an error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection Rate Overall:  0.7406333333333334\n",
      "\n",
      "\n",
      "Evaluation of  FPRP -constrained classifier by race:\n",
      "Selection Rate By Group:  sensitive_feature_0\n",
      "0    0.467569\n",
      "1    0.777236\n",
      "Name: selection_rate, dtype: object \n",
      "\n",
      "EVALUATION FOR BLACK GROUP\n",
      "[[1742  612]\n",
      " [ 146 1046]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.74      0.82      2354\n",
      "           1       0.63      0.88      0.73      1192\n",
      "\n",
      "    accuracy                           0.79      3546\n",
      "   macro avg       0.78      0.81      0.78      3546\n",
      "weighted avg       0.82      0.79      0.79      3546\n",
      "\n",
      "TNR=TN/(TN+FP)=  0.740016992353441\n",
      "TPR=TP/(FP+FN)=  0.87751677852349\n",
      "FNER=FN/(FN+TP)=  0.12248322147651007\n",
      "FPER=FP/(FP+TN)=  0.2599830076465591\n",
      "F1 score micro: \n",
      "0.7862380146644106\n",
      "F1 score weighted: \n",
      "0.7919727067804931\n",
      "F1 score binary: \n",
      "0.7340350877192983\n",
      "\n",
      "EVALUATION FOR WHITE GROUP\n",
      "[[ 4651  1675]\n",
      " [ 1242 18886]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      6326\n",
      "           1       0.92      0.94      0.93     20128\n",
      "\n",
      "    accuracy                           0.89     26454\n",
      "   macro avg       0.85      0.84      0.84     26454\n",
      "weighted avg       0.89      0.89      0.89     26454\n",
      "\n",
      "TNR=TN/(TN+FP)=  0.7352197281062283\n",
      "TPR=TP/(FP+FN)=  0.9382949125596184\n",
      "FNER=FN/(FN+TP)=  0.061705087440381556\n",
      "FPER=FP/(FP+TN)=  0.26478027189377173\n",
      "F1 score micro: \n",
      "0.8897331216451199\n",
      "F1 score weighted: \n",
      "0.888366092523213\n",
      "F1 score binary: \n",
      "0.9283098626164319\n",
      "\n",
      "\n",
      "Fairness metric evaluation of  FPRP -constrained classifier\n",
      "DP Difference:  0.30966686482054795\n",
      "-->difference of 0 means that all groups have the same selection rate\n",
      "DP Ratio: 0.6015793374853959\n",
      "-->ratio of 1 means that all groups have the same selection rate \n",
      "\n",
      "EOD Difference:  0.06077813403612842\n",
      "-->difference of 0 means that all groups have the same TN, TN, FP, and FN rates\n",
      "EOD Ratio: 0.9352249135931805\n",
      "-->ratio of 1 means that all groups have the same TN, TN, FP, and FN rates rates \n",
      "\n",
      "The delayed impact of the black group is:  -3.7648054145516077\n",
      "The delayed impact of the white group is:  44.046268995237014\n"
     ]
    }
   ],
   "source": [
    "eg_fprp = add_contraint(model, 'FPRP', 'EG', X_train, y_train, race_train, race_test, X_test, y_test, y_predict, sample_weight_test, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Rate Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exponentiated Gradient Reduction Alg is used here with  ERP  as the fairness constraint.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2bab57bb4012>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meg_erp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_contraint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ERP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'EG'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrace_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrace_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/git_repositories/delayedimpact/notebooks/impt_functions.py\u001b[0m in \u001b[0;36madd_contraint\u001b[0;34m(model, constraint_str, reduction_alg, X_train, y_train, race_train, race_test, X_test, y_test, y_predict, sample_weight_test, dashboard_bool)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ISSUE: need to put in a valid reduction_alg parameter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0mmitigator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensitive_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrace_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0my_pred_mitigated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmitigator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/fairlearn/reductions/_exponentiated_gradient/exponentiated_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;31m# select classifier according to best_h method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlagrangian\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py\u001b[0m in \u001b[0;36mbest_h\u001b[0;34m(self, lambda_vec)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0mvector\u001b[0m \u001b[0mof\u001b[0m \u001b[0mLagrange\u001b[0m \u001b[0mmultipliers\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mlambda_vec\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \"\"\"\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_oracle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py\u001b[0m in \u001b[0;36m_call_oracle\u001b[0;34m(self, lambda_vec)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0moracle_call_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_weight_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mredW\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle_execution_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moracle_call_start_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_oracle_calls\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \"\"\"\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    899\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eg_erp = add_contraint(model, 'ERP', 'EG', X_train, y_train, race_train, race_test, X_test, y_test, y_predict, sample_weight_test, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bounded Group Loss (TODO: issue, need to figure out loss parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_contraint(model, 'BGL', 'EG', X_train, y_train, race_train, race_test, X_test, y_test, y_predict, sample_weight_test, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Reduction Alg for Adding Fairness Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographic Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_dp = add_contraint(model, 'DP', 'GS', X_train, y_train, race_train, race_test, X_test, y_test, y_predict, sample_weight_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can examine the values of lambda_i chosen for us:\n",
    "lambda_vecs = gs_dp.lambda_vecs_\n",
    "print(lambda_vecs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few cells come from: https://github.com/fairlearn/fairlearn/blob/main/notebooks/Binary%20Classification%20with%20the%20UCI%20Credit-card%20Default%20Dataset.ipynb\n",
    "\n",
    "Note: we train multiple models corresponding to different trade-off points between the performance metric (balanced accuracy) and fairness metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_show(gs_dp, demographic_parity_difference, y_predict, X_test, y_test, race_test, 'DemParityDifference','GS DPD', models_dict, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict.pop('GS DPD')\n",
    "models_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equalized Odds Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_eo = add_contraint(model, 'EO', 'GS', X_train, y_train, race_train, race_test, X_test, y_test, y_predict, sample_weight_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can examine the values of lambda_i chosen for us:\n",
    "lambda_vecs = gs_eo.lambda_vecs_\n",
    "print(lambda_vecs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_show(gs_eo, equalized_odds_difference, y_predict, X_test, y_test, race_test, 'EOddsDifference','GS EO', models_dict, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict.pop('GS EO')\n",
    "models_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EOO (True Positive Rate Parity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_tprp = add_contraint(model, 'TPRP', 'GS', X_train, y_train, race_train, race_test, X_test, y_test, y_predict, sample_weight_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can examine the values of lambda_i chosen for us:\n",
    "lambda_vecs = gs_tprp.lambda_vecs_\n",
    "print(lambda_vecs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_show(gs_tprp, true_positive_rate_difference, y_predict, X_test, y_test, race_test, 'TPRPDifference','GS TPRP', models_dict, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict.pop('GS TPRP')\n",
    "models_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Positive Rate Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_fprp = add_contraint(model, 'FPRP', 'GS', X_train, y_train, race_train, race_test, X_test, y_test, y_predict, sample_weight_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can examine the values of lambda_i chosen for us:\n",
    "lambda_vecs = gs_fprp.lambda_vecs_\n",
    "print(lambda_vecs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: the below models are the same!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_show(gs_fprp, false_positive_rate_difference, y_predict, X_test, y_test, race_test, 'FPRPDifference','GS FPRP', models_dict, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict.pop('GS FPRP')\n",
    "models_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Rate Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_erp = add_contraint(model, 'ERP', 'GS', X_train, y_train, race_train, race_test, X_test, y_test, y_predict, sample_weight_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can examine the values of lambda_i chosen for us:\n",
    "lambda_vecs = gs_erp.lambda_vecs_\n",
    "print(lambda_vecs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairlearn doesnt have an erp difference metric for the below\n",
    "#grid_search_show(gs_erp, error_difference, y_predict, X_test, y_test, race_test, 'ERDifference','GS ERP', models_dict, 0.3)\n",
    "#models_dict.pop('GS FPRP')\n",
    "#models_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bounded Group Loss (issue, need to figure out loss parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gs_bgl = add_contraint(model, 'BGL', 'GS', X_train, y_train, race_train, race_test, X_test, y_test, y_predict, sample_weight_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can examine the values of lambda_i chosen for us:\n",
    "#lambda_vecs = gs_dp.lambda_vecs_\n",
    "#print(lambda_vecs[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
