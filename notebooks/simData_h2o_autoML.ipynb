{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start H2O\n",
    "\n",
    "Import the **h2o** Python module and `H2OAutoML` class and initialize a local H2O cluster.\n",
    "\n",
    "NOTE: the structure of this code is primarily from the h2o AutoML regression ipynb tutorial and adapted to run with my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>42 mins 10 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/London</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.32.1.1</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>19 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_mackenzie_bbmmpt</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>7.773 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.8.5 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O_cluster_uptime:         42 mins 10 secs\n",
       "H2O_cluster_timezone:       Europe/London\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.32.1.1\n",
       "H2O_cluster_version_age:    19 days\n",
       "H2O_cluster_name:           H2O_from_python_mackenzie_bbmmpt\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    7.773 Gb\n",
       "H2O_cluster_total_cores:    12\n",
       "H2O_cluster_allowed_cores:  12\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.8.5 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Group A is Black\n",
    "# Group B is White\n",
    "dataA_path = \"/home/mackenzie/git_repositories/delayedimpact/data/simulated_data/simData_groupA_black.csv\"\n",
    "#dataB_path = \"/home/mackenzie/git_repositories/delayedimpact/data/simulated_data/simData_groupB_black.csv\"\n",
    "\n",
    "# Load data into H2O\n",
    "df_A = h2o.import_file(dataA_path)\n",
    "#df_B = h2o.import_file(dataB_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:1000\n",
      "Cols:2\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>score             </th><th>repay_probability  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>real              </td><td>real               </td></tr>\n",
       "<tr><td>mins   </td><td>311.9047619047619 </td><td>1.2000000000000028 </td></tr>\n",
       "<tr><td>mean   </td><td>633.662900804343  </td><td>70.83487000000005  </td></tr>\n",
       "<tr><td>maxs   </td><td>841.2280701754386 </td><td>99.05              </td></tr>\n",
       "<tr><td>sigma  </td><td>130.08983997452646</td><td>34.00573837200606  </td></tr>\n",
       "<tr><td>zeros  </td><td>0                 </td><td>0                  </td></tr>\n",
       "<tr><td>missing</td><td>0                 </td><td>0                  </td></tr>\n",
       "<tr><td>0      </td><td>323.8095238095238 </td><td>1.2000000000000028 </td></tr>\n",
       "<tr><td>1      </td><td>323.8095238095238 </td><td>1.2000000000000028 </td></tr>\n",
       "<tr><td>2      </td><td>323.8095238095238 </td><td>1.2000000000000028 </td></tr>\n",
       "<tr><td>3      </td><td>323.8095238095238 </td><td>1.2000000000000028 </td></tr>\n",
       "<tr><td>4      </td><td>347.6190476190476 </td><td>2.069999999999993  </td></tr>\n",
       "<tr><td>5      </td><td>354.76190476190476</td><td>2.510000000000005  </td></tr>\n",
       "<tr><td>6      </td><td>360.7142857142857 </td><td>2.9399999999999977 </td></tr>\n",
       "<tr><td>7      </td><td>366.6666666666667 </td><td>3.3799999999999955 </td></tr>\n",
       "<tr><td>8      </td><td>372.6190476190476 </td><td>3.8199999999999927 </td></tr>\n",
       "<tr><td>9      </td><td>372.6190476190476 </td><td>3.8199999999999927 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q: maybe I should cut down on the decimals included?? That could be causing the regression models I was using before to suffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's identify the response column and save the column name as `y`.  In this dataset, we will use all columns except the response as predictors, so we can skip setting the `x` argument explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"repay_probability\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's split the data into two frames, a `train` (80%) and a `test` frame (20%).  The `test` frame will be used to score the leaderboard and to demonstrate how to generate predictions using an AutoML leader model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = df.split_frame(ratios = [0.8], seed = 1)\n",
    "train = splits[0]\n",
    "test = splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run AutoML \n",
    "\n",
    "Run AutoML, stopping after 60 seconds.  The `max_runtime_secs` argument provides a way to limit the AutoML run by time.  When using a time-limited stopping criterion, the number of models train will vary between runs.  If different hardware is used or even if the same machine is used but the available compute resources on that machine are not the same between runs, then AutoML may be able to train more models on one run vs another. \n",
    "\n",
    "The `test` frame is passed explicitly to the `leaderboard_frame` argument here, which means that instead of using cross-validated metrics, we use test set metrics for generating the leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "aml = H2OAutoML(max_runtime_secs = 60, seed = 1, project_name = \"repay_groupA_train\")\n",
    "aml.train(y = y, training_frame = train, leaderboard_frame = test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes, we will also execute a second AutoML run, this time providing the original, full dataset, `df` (without passing a `leaderboard_frame`).  This is a more efficient use of our data since we can use 100% of the data for training, rather than 80% like we did above.  This time our leaderboard will use cross-validated metrics.\n",
    "\n",
    "*Note: Using an explicit `leaderboard_frame` for scoring may be useful in some cases, which is why the option is available.*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "aml2 = H2OAutoML(max_runtime_secs = 60, seed = 1, project_name = \"repay_groupA_full_data\")\n",
    "aml2.train(y = y, training_frame = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leaderboard\n",
    "\n",
    "Next, we will view the AutoML Leaderboard.  Since we specified a `leaderboard_frame` in the `H2OAutoML.train()` method for scoring and ranking the models, the AutoML leaderboard uses the performance on this data to rank the models.\n",
    "\n",
    "We can see that the results are better when the full dataset is used for training.  \n",
    "\n",
    "In the case of regression, the default ranking metric is mean residual deviance.  In the future, the user will be able to specify any of the H2O metrics so that different metrics can be used to generate rankings on the leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">  mean_residual_deviance</th><th style=\"text-align: right;\">   rmse</th><th style=\"text-align: right;\">    mse</th><th style=\"text-align: right;\">    mae</th><th style=\"text-align: right;\">   rmsle</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20210414_161300   </td><td style=\"text-align: right;\">                 9.1217 </td><td style=\"text-align: right;\">3.02022</td><td style=\"text-align: right;\">9.1217 </td><td style=\"text-align: right;\">1.57776</td><td style=\"text-align: right;\">0.112103</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210414_161300_model_5         </td><td style=\"text-align: right;\">                 9.15735</td><td style=\"text-align: right;\">3.02611</td><td style=\"text-align: right;\">9.15735</td><td style=\"text-align: right;\">1.59303</td><td style=\"text-align: right;\">0.113978</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20210414_161300</td><td style=\"text-align: right;\">                 9.17336</td><td style=\"text-align: right;\">3.02876</td><td style=\"text-align: right;\">9.17336</td><td style=\"text-align: right;\">1.60447</td><td style=\"text-align: right;\">0.112205</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210414_161300_model_1         </td><td style=\"text-align: right;\">                 9.30638</td><td style=\"text-align: right;\">3.05064</td><td style=\"text-align: right;\">9.30638</td><td style=\"text-align: right;\">1.6044 </td><td style=\"text-align: right;\">0.107969</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210414_161300_model_6         </td><td style=\"text-align: right;\">                 9.34113</td><td style=\"text-align: right;\">3.05633</td><td style=\"text-align: right;\">9.34113</td><td style=\"text-align: right;\">1.54901</td><td style=\"text-align: right;\">0.108889</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210414_161300_model_7         </td><td style=\"text-align: right;\">                 9.47685</td><td style=\"text-align: right;\">3.07845</td><td style=\"text-align: right;\">9.47685</td><td style=\"text-align: right;\">1.60668</td><td style=\"text-align: right;\">0.1142  </td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210414_161300_model_4         </td><td style=\"text-align: right;\">                 9.56512</td><td style=\"text-align: right;\">3.09275</td><td style=\"text-align: right;\">9.56512</td><td style=\"text-align: right;\">1.6562 </td><td style=\"text-align: right;\">0.119363</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20210414_161300_model_9     </td><td style=\"text-align: right;\">                 9.56852</td><td style=\"text-align: right;\">3.0933 </td><td style=\"text-align: right;\">9.56852</td><td style=\"text-align: right;\">1.57901</td><td style=\"text-align: right;\">0.113015</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20210414_161300_model_5     </td><td style=\"text-align: right;\">                 9.66351</td><td style=\"text-align: right;\">3.10862</td><td style=\"text-align: right;\">9.66351</td><td style=\"text-align: right;\">1.60561</td><td style=\"text-align: right;\">0.101056</td></tr>\n",
       "<tr><td>GBM_2_AutoML_20210414_161300                       </td><td style=\"text-align: right;\">                 9.70189</td><td style=\"text-align: right;\">3.11479</td><td style=\"text-align: right;\">9.70189</td><td style=\"text-align: right;\">1.56912</td><td style=\"text-align: right;\">0.10384 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leaderboard.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will view a snapshot of the top models.  Here we should see the two Stacked Ensembles at or near the top of the leaderboard.  Stacked Ensembles can almost always outperform a single model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">  mean_residual_deviance</th><th style=\"text-align: right;\">   rmse</th><th style=\"text-align: right;\">    mse</th><th style=\"text-align: right;\">    mae</th><th style=\"text-align: right;\">   rmsle</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>GBM_grid__1_AutoML_20210414_162119_model_1         </td><td style=\"text-align: right;\">                 8.25813</td><td style=\"text-align: right;\">2.8737 </td><td style=\"text-align: right;\">8.25813</td><td style=\"text-align: right;\">1.53062</td><td style=\"text-align: right;\">0.114514</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20210414_162119</td><td style=\"text-align: right;\">                 8.32766</td><td style=\"text-align: right;\">2.88577</td><td style=\"text-align: right;\">8.32766</td><td style=\"text-align: right;\">1.54941</td><td style=\"text-align: right;\">0.113013</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210414_162119_model_6         </td><td style=\"text-align: right;\">                 8.33682</td><td style=\"text-align: right;\">2.88736</td><td style=\"text-align: right;\">8.33682</td><td style=\"text-align: right;\">1.48992</td><td style=\"text-align: right;\">0.116533</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20210414_162119   </td><td style=\"text-align: right;\">                 8.354  </td><td style=\"text-align: right;\">2.89033</td><td style=\"text-align: right;\">8.354  </td><td style=\"text-align: right;\">1.54947</td><td style=\"text-align: right;\">0.114976</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210414_162119_model_5         </td><td style=\"text-align: right;\">                 8.38072</td><td style=\"text-align: right;\">2.89495</td><td style=\"text-align: right;\">8.38072</td><td style=\"text-align: right;\">1.52868</td><td style=\"text-align: right;\">0.125859</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210414_162119_model_7         </td><td style=\"text-align: right;\">                 8.38596</td><td style=\"text-align: right;\">2.89585</td><td style=\"text-align: right;\">8.38596</td><td style=\"text-align: right;\">1.5274 </td><td style=\"text-align: right;\">0.125065</td></tr>\n",
       "<tr><td>GBM_4_AutoML_20210414_162119                       </td><td style=\"text-align: right;\">                 8.41215</td><td style=\"text-align: right;\">2.90037</td><td style=\"text-align: right;\">8.41215</td><td style=\"text-align: right;\">1.4561 </td><td style=\"text-align: right;\">0.112324</td></tr>\n",
       "<tr><td>GBM_3_AutoML_20210414_162119                       </td><td style=\"text-align: right;\">                 8.4311 </td><td style=\"text-align: right;\">2.90364</td><td style=\"text-align: right;\">8.4311 </td><td style=\"text-align: right;\">1.4655 </td><td style=\"text-align: right;\">0.112563</td></tr>\n",
       "<tr><td>GBM_2_AutoML_20210414_162119                       </td><td style=\"text-align: right;\">                 8.44393</td><td style=\"text-align: right;\">2.90584</td><td style=\"text-align: right;\">8.44393</td><td style=\"text-align: right;\">1.48223</td><td style=\"text-align: right;\">0.112353</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210414_162119_model_4         </td><td style=\"text-align: right;\">                 8.50258</td><td style=\"text-align: right;\">2.91592</td><td style=\"text-align: right;\">8.50258</td><td style=\"text-align: right;\">1.54432</td><td style=\"text-align: right;\">0.127694</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml2.leaderboard.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Using Leader Model\n",
    "\n",
    "If you need to generate predictions on a test set, you can make predictions on the `\"H2OAutoML\"` object directly, or on the leader model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">  3.91525</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.95684</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  8.37621</td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 17.2936 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 19.3099 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 21.0827 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 21.0827 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 35.0734 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 35.7597 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 60.5727 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = aml.predict(test)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If needed, the standard `model_performance()` method can be applied to the AutoML leader model and a test set to generate an H2O model performance object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsRegressionGLM: stackedensemble\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 9.12170436098709\n",
      "RMSE: 3.020215946085162\n",
      "MAE: 1.57775843435667\n",
      "RMSLE: 0.11210334774997908\n",
      "R^2: 0.9912216659230666\n",
      "Mean Residual Deviance: 9.12170436098709\n",
      "Null degrees of freedom: 205\n",
      "Residual degrees of freedom: 194\n",
      "Null deviance: 214883.8855244431\n",
      "Residual deviance: 1879.0710983633408\n",
      "AIC: 1065.9979493528472\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf = aml.leader.model_performance(test)\n",
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
