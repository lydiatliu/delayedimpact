{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from fairlearn.reductions import ExponentiatedGradient, GridSearch, DemographicParity, EqualizedOdds, \\\n",
    "    TruePositiveRateParity, FalsePositiveRateParity, ErrorRateParity, BoundedGroupLoss\n",
    "from fairlearn.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Extract data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      score  repay_probability  race  repay_indices\n",
      "0       610              78.90     1              1\n",
      "1       568              47.77     0              0\n",
      "2       750              98.13     1              1\n",
      "3       775              98.45     1              1\n",
      "4       704              95.88     1              1\n",
      "...     ...                ...   ...            ...\n",
      "9995    832              98.99     1              1\n",
      "9996    416              10.91     1              0\n",
      "9997    444              14.63     1              0\n",
      "9998    778              98.47     1              1\n",
      "9999    738              97.68     1              1\n",
      "\n",
      "[10000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/home/mackenzie/git_repositories/delayedimpact/data/simData_oom10.csv')\n",
    "data[['score', 'race']] = data[['score', 'race']].astype(int)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prepare data into train/test form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[['score', 'race']].values\n",
    "y = data['repay_indices'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# collect our sensitive attribute\n",
    "race_train = X_train[:, 1]\n",
    "race_test = X_test[:, 1]\n",
    "\n",
    "# for fairlearn mitigator algs to work, I have to weigh the data\n",
    "# for now I'm weighing everything the same\n",
    "# TODO: add correct sample weights according to, http://www.surveystar.com/startips/weighting.pdf\n",
    "#       and https://www.nlsinfo.org/content/cohorts/nlsy97/using-and-understanding-the-data/sample-weights-design-effects/page/0/0/#intro\n",
    "sample_weight_train = np.ones(shape=(len(y_train),))\n",
    "sample_weight_test = np.ones(shape=(len(y_test),))\n",
    "#sample_weight[y_train[:,1] == 0] = 1.5 \n",
    "\n",
    "# Below example from: https://androidkt.com/set-sample-weight-in-keras/\n",
    "#sample_weight[y_train == 3] = 1.5\n",
    "\n",
    "# Q: do I need to scale the data??\n",
    "# Standardize features by removing mean and scaling to unit variance:\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(X_train)\n",
    "#X_train = scaler.transform(X_train)\n",
    "#X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_outcome_rates(y_true, y_pred, sample_weight):\n",
    "    fner = false_negative_rate(y_true, y_pred, pos_label=1, sample_weight=sample_weight)\n",
    "    print('FNER', fner)\n",
    "    fper = false_positive_rate(y_true, y_pred, pos_label=1, sample_weight=sample_weight)\n",
    "    print('FPER', fper)\n",
    "    tnr = true_negative_rate(y_true, y_pred, pos_label=1, sample_weight=sample_weight)\n",
    "    print('TNR', tnr)\n",
    "    tpr = true_positive_rate(y_true, y_pred, pos_label=1, sample_weight=sample_weight)\n",
    "    print('TPR', tpr)\n",
    "    return\n",
    "\n",
    "def evaluation_by_race(X_test, y_test, y_predict, sample_weight):\n",
    "\n",
    "    y_test_black, y_pred_black, sw_black, y_test_white, y_pred_white, sw_white = [],[],[],[],[],[]\n",
    "    \n",
    "    # splitting up the y_test and y_pred values by race to then use for race specific classification reports\n",
    "    for index, race in enumerate(race_test):\n",
    "        if(race == 0):  # black\n",
    "            y_test_black.append(y_test[index])\n",
    "            y_pred_black.append(y_predict[index])\n",
    "            sw_black.append(sample_weight[index])\n",
    "        elif(race == 1):  # white\n",
    "            y_test_white.append(y_test[index])\n",
    "            y_pred_white.append(y_predict[index])\n",
    "            sw_white.append(sample_weight[index])\n",
    "\n",
    "        else:\n",
    "            print('You should not end up here...')\n",
    "            \n",
    "    print('EVALUATION FOR BLACK GROUP')\n",
    "    print(confusion_matrix(y_test_black, y_pred_black))\n",
    "    print(classification_report(y_test_black, y_pred_black)) \n",
    "    evaluation_outcome_rates(y_test_black, y_pred_black, sw_black)\n",
    "    \n",
    "    print('\\nEVALUATION FOR WHITE GROUP')\n",
    "    print(confusion_matrix(y_test_white, y_pred_white))\n",
    "    print(classification_report(y_test_white, y_pred_white))\n",
    "    evaluation_outcome_rates(y_test_white, y_pred_white, sw_white)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://fairlearn.org/v0.5.0/api_reference/fairlearn.metrics.html\n",
    "\n",
    "def add_contraint(constraint_str, reduction_alg, X_train, y_train, race_train, X_test, y_test, sample_weight_test):\n",
    "    # set seed for consistent results with ExponentiatedGradient\n",
    "    np.random.seed(0)  \n",
    "    \n",
    "    if constraint_str=='DP':\n",
    "        constraint = DemographicParity()\n",
    "    elif constraint_str=='EO':\n",
    "        constraint = EqualizedOdds()\n",
    "    elif constraint_str=='TPRP':\n",
    "        constraint = TruePositiveRateParity()\n",
    "    elif constraint_str=='FPRP':\n",
    "        constraint = FalsePositiveRateParity()\n",
    "    elif constraint_str=='ERP':\n",
    "        constraint = ErrorRateParity()\n",
    "    elif constraint_str=='BGL':\n",
    "        # Parameters: \n",
    "        #   loss : {SquareLoss, AbsoluteLoss}\n",
    "        #   A loss object with an `eval` method, e.g. `SquareLoss` or `AbsoluteLoss`\n",
    "        constraint = BoundedGroupLoss('SquareLoss')\n",
    "    \n",
    "    if reduction_alg=='EG':\n",
    "        mitigator = ExponentiatedGradient(model, constraint)\n",
    "        print('Exponentiated Gradient Reduction Alg is used here with ', constraint_str, ' as the fairness constraint.\\n')\n",
    "    elif reduction_alg=='GS':\n",
    "        mitigator = GridSearch(model, constraint)\n",
    "        print('Grid Search Reduction Alg is used here with ', constraint_str, ' as the fairness constraint.\\n')\n",
    "    else:\n",
    "        print('ISSUE: need to put in a valid reduction_alg parameter')\n",
    "\n",
    "        \n",
    "    mitigator.fit(X_train, y_train, sensitive_features=race_train)\n",
    "    y_pred_mitigated = mitigator.predict(X_test)\n",
    "    \n",
    "    print('Evaluation of ', constraint_str, '-constrained classifier overall:')\n",
    "    print(confusion_matrix(y_test, y_pred_mitigated))\n",
    "    print(classification_report(y_test, y_pred_mitigated)) \n",
    "    evaluation_outcome_rates(y_test, y_pred_mitigated, sample_weight_test)\n",
    "    print('\\n')\n",
    "    \n",
    "    print('Evaluation of ', constraint_str, '-constrained classifier by race:')\n",
    "    evaluation_by_race(X_test, y_test, y_pred_mitigated, sample_weight_test)\n",
    "    print('\\n')\n",
    "    \n",
    "    print('Fairness metric evaluation of ', constraint_str, '-constrained classifier')\n",
    "    print_fairness_metrics(y_true=y_test, y_pred=y_pred_mitigated, sensitive_features=race_test)\n",
    "    return\n",
    "\n",
    "\n",
    "def print_fairness_metrics(y_true, y_pred, sensitive_features):\n",
    "    sr_mitigated = MetricFrame(metric=selection_rate, y_true=y_true, y_pred=y_pred, sensitive_features=sensitive_features)\n",
    "    print('Selection Rate Overall: ', sr_mitigated.overall)\n",
    "    print('Selection Rate By Group: ',sr_mitigated.by_group, '\\n')\n",
    "\n",
    "    print('Note: difference of 0 means that all groups have the same selection rate.')\n",
    "    dp_diff = demographic_parity_difference(y_true=y_true, y_pred=y_pred, sensitive_features=sensitive_features)\n",
    "    print('DP Difference: ', dp_diff)\n",
    "    print('Note: ratio of 1 means that all groups have the same selection rate.')\n",
    "    dp_ratio = demographic_parity_ratio(y_true=y_true, y_pred=y_pred, sensitive_features=sensitive_features)\n",
    "    print('DP Ratio:', dp_ratio, '\\n')\n",
    "    \n",
    "    print('Note: difference of 0 means that all groups have the same TN, TN, FP, and FN rates.')\n",
    "    eod_diff = equalized_odds_difference(y_true=y_true, y_pred=y_pred, sensitive_features=sensitive_features)\n",
    "    print('EOD Difference: ', eod_diff)\n",
    "    print('Note: ratio of 1 means that all groups have the same TN, TN, FP, and FN rates rates.')\n",
    "    eod_ratio = equalized_odds_ratio(y_true=y_true, y_pred=y_pred, sensitive_features=sensitive_features)\n",
    "    print('EOD Ratio:', eod_ratio, '\\n')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOS:\n",
    "- Get fairlearn widget to work below by updating the widget/using the raiwidgets tool?\n",
    "- Add code pipeline for last 3 classifiers \n",
    "- Add the delayed impact results to the evaluation of results\n",
    "- Calculate sample weights and make that a boolean/if+else option in the code and/or make a new notebook?\n",
    "- Try to figure out bounded group loss metric, need a loss parameter. Definition: 'asks that the prediction error restricted to any protected group remain below some pre-determined level' from https://arxiv.org/abs/1905.12843\n",
    "\n",
    "\n",
    "# Notes:\n",
    "- Fairness constraint options: DP refers to demographic parity, EO to equalized odds, TPRP to true positive rate parity, FPRP to false positive rate parity, ERP to error rate parity, and BGL to bounded group loss.\n",
    "- Couldn't use K-nearest neighbors as an ML classifier bc the fit function does not take in sample weights parameter\n",
    "- CAN use (their fit functions take in sample weights): gaussian naive bayes, decision tree, logistic regression, and svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes classifier (Fairlearn used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GNB classifier + Collect Predictions\n",
    "NOTE: atm sample_weight are all 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classifier:\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train the classifier:\n",
    "model = gnb.fit(X_train, y_train, sample_weight_train)\n",
    "\n",
    "# Make predictions with the classifier:\n",
    "y_predict = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of classifier overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 617  232]\n",
      " [ 188 1963]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       849\n",
      "           1       0.89      0.91      0.90      2151\n",
      "\n",
      "    accuracy                           0.86      3000\n",
      "   macro avg       0.83      0.82      0.82      3000\n",
      "weighted avg       0.86      0.86      0.86      3000\n",
      "\n",
      "FNER 0.08740120874012088\n",
      "FPER 0.27326266195524146\n",
      "TNR 0.7267373380447585\n",
      "TPR 0.9125987912598791\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(classification_report(y_test, y_predict)) \n",
    "evaluation_outcome_rates(y_test, y_predict, sample_weight_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of classifier by race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION FOR BLACK GROUP\n",
      "[[233   0]\n",
      " [122   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.79       233\n",
      "           1       1.00      0.03      0.06       126\n",
      "\n",
      "    accuracy                           0.66       359\n",
      "   macro avg       0.83      0.52      0.43       359\n",
      "weighted avg       0.78      0.66      0.54       359\n",
      "\n",
      "FNER 0.9682539682539683\n",
      "FPER 0.0\n",
      "TNR 1.0\n",
      "TPR 0.031746031746031744\n",
      "\n",
      "EVALUATION FOR WHITE GROUP\n",
      "[[ 384  232]\n",
      " [  66 1959]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.62      0.72       616\n",
      "           1       0.89      0.97      0.93      2025\n",
      "\n",
      "    accuracy                           0.89      2641\n",
      "   macro avg       0.87      0.80      0.82      2641\n",
      "weighted avg       0.88      0.89      0.88      2641\n",
      "\n",
      "FNER 0.03259259259259259\n",
      "FPER 0.37662337662337664\n",
      "TNR 0.6233766233766234\n",
      "TPR 0.9674074074074074\n"
     ]
    }
   ],
   "source": [
    "evaluation_by_race(X_test, y_test, y_predict, sample_weight_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Metric Evaluation of classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection Rate Overall:  0.7316666666666667\n",
      "Selection Rate By Group:  sensitive_feature_0\n",
      "0    0.0111421\n",
      "1      0.82961\n",
      "Name: selection_rate, dtype: object \n",
      "\n",
      "Note: difference of 0 means that all groups have the same selection rate.\n",
      "DP Difference:  0.8184679349322184\n",
      "Note: ratio of 1 means that all groups have the same selection rate.\n",
      "DP Ratio: 0.013430480987681945 \n",
      "\n",
      "Note: difference of 0 means that all groups have the same TN, TN, FP, and FN rates.\n",
      "EOD Difference:  0.9356613756613756\n",
      "Note: ratio of 1 means that all groups have the same TN, TN, FP, and FN rates rates.\n",
      "EOD Ratio: 0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_fairness_metrics(y_test, y_predict, race_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponentiated Gradient Reduction Alg for Adding Fairness Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographic Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exponentiated Gradient Reduction Alg is used here with  DP  as the fairness constraint.\n",
      "\n",
      "Evaluation of  DP -constrained classifier overall:\n",
      "[[ 615  234]\n",
      " [ 909 1242]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.72      0.52       849\n",
      "           1       0.84      0.58      0.68      2151\n",
      "\n",
      "    accuracy                           0.62      3000\n",
      "   macro avg       0.62      0.65      0.60      3000\n",
      "weighted avg       0.72      0.62      0.64      3000\n",
      "\n",
      "FNER 0.4225941422594142\n",
      "FPER 0.2756183745583039\n",
      "TNR 0.7243816254416962\n",
      "TPR 0.5774058577405857\n",
      "\n",
      "\n",
      "Evaluation of  DP -constrained classifier by race:\n",
      "EVALUATION FOR BLACK GROUP\n",
      "[[114 119]\n",
      " [ 72  54]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.49      0.54       233\n",
      "           1       0.31      0.43      0.36       126\n",
      "\n",
      "    accuracy                           0.47       359\n",
      "   macro avg       0.46      0.46      0.45       359\n",
      "weighted avg       0.51      0.47      0.48       359\n",
      "\n",
      "FNER 0.5714285714285714\n",
      "FPER 0.5107296137339056\n",
      "TNR 0.4892703862660944\n",
      "TPR 0.42857142857142855\n",
      "\n",
      "EVALUATION FOR WHITE GROUP\n",
      "[[ 501  115]\n",
      " [ 837 1188]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.81      0.51       616\n",
      "           1       0.91      0.59      0.71      2025\n",
      "\n",
      "    accuracy                           0.64      2641\n",
      "   macro avg       0.64      0.70      0.61      2641\n",
      "weighted avg       0.79      0.64      0.67      2641\n",
      "\n",
      "FNER 0.41333333333333333\n",
      "FPER 0.18668831168831168\n",
      "TNR 0.8133116883116883\n",
      "TPR 0.5866666666666667\n",
      "\n",
      "\n",
      "Fairness metric evaluation of  DP -constrained classifier\n",
      "Selection Rate Overall:  0.492\n",
      "Selection Rate By Group:  sensitive_feature_0\n",
      "0    0.481894\n",
      "1    0.493374\n",
      "Name: selection_rate, dtype: object \n",
      "\n",
      "Note: difference of 0 means that all groups have the same selection rate.\n",
      "DP Difference:  0.011479571657144305\n",
      "Note: ratio of 1 means that all groups have the same selection rate.\n",
      "DP Ratio: 0.9767325028806462 \n",
      "\n",
      "Note: difference of 0 means that all groups have the same TN, TN, FP, and FN rates.\n",
      "EOD Difference:  0.3240413020455939\n",
      "Note: ratio of 1 means that all groups have the same TN, TN, FP, and FN rates rates.\n",
      "EOD Ratio: 0.36553257666703043 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_contraint('DP', 'EG', X_train, y_train, race_train, X_test, y_test, sample_weight_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equalized Odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exponentiated Gradient Reduction Alg is used here with  EO  as the fairness constraint.\n",
      "\n",
      "Evaluation of  EO -constrained classifier overall:\n",
      "[[ 602  247]\n",
      " [ 292 1859]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69       849\n",
      "           1       0.88      0.86      0.87      2151\n",
      "\n",
      "    accuracy                           0.82      3000\n",
      "   macro avg       0.78      0.79      0.78      3000\n",
      "weighted avg       0.82      0.82      0.82      3000\n",
      "\n",
      "FNER 0.13575081357508137\n",
      "FPER 0.29093050647820967\n",
      "TNR 0.7090694935217904\n",
      "TPR 0.8642491864249187\n",
      "\n",
      "\n",
      "Evaluation of  EO -constrained classifier by race:\n",
      "EVALUATION FOR BLACK GROUP\n",
      "[[163  70]\n",
      " [ 17 109]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.70      0.79       233\n",
      "           1       0.61      0.87      0.71       126\n",
      "\n",
      "    accuracy                           0.76       359\n",
      "   macro avg       0.76      0.78      0.75       359\n",
      "weighted avg       0.80      0.76      0.76       359\n",
      "\n",
      "FNER 0.1349206349206349\n",
      "FPER 0.30042918454935624\n",
      "TNR 0.6995708154506438\n",
      "TPR 0.8650793650793651\n",
      "\n",
      "EVALUATION FOR WHITE GROUP\n",
      "[[ 439  177]\n",
      " [ 275 1750]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.71      0.66       616\n",
      "           1       0.91      0.86      0.89      2025\n",
      "\n",
      "    accuracy                           0.83      2641\n",
      "   macro avg       0.76      0.79      0.77      2641\n",
      "weighted avg       0.84      0.83      0.83      2641\n",
      "\n",
      "FNER 0.13580246913580246\n",
      "FPER 0.28733766233766234\n",
      "TNR 0.7126623376623377\n",
      "TPR 0.8641975308641975\n",
      "\n",
      "\n",
      "Fairness metric evaluation of  EO -constrained classifier\n",
      "Selection Rate Overall:  0.702\n",
      "Selection Rate By Group:  sensitive_feature_0\n",
      "0    0.498607\n",
      "1    0.729648\n",
      "Name: selection_rate, dtype: object \n",
      "\n",
      "Note: difference of 0 means that all groups have the same selection rate.\n",
      "DP Difference:  0.23104061831900846\n",
      "Note: ratio of 1 means that all groups have the same selection rate.\n",
      "DP Ratio: 0.683353257405033 \n",
      "\n",
      "Note: difference of 0 means that all groups have the same TN, TN, FP, and FN rates.\n",
      "EOD Difference:  0.013091522211693907\n",
      "Note: ratio of 1 means that all groups have the same TN, TN, FP, and FN rates rates.\n",
      "EOD Ratio: 0.9564239332096475 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_contraint('EO', 'EG', X_train, y_train, race_train, X_test, y_test, sample_weight_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(fairlearn.reductions._moments.utility_parity.DemographicParity,\n",
       " fairlearn.reductions._moments.utility_parity.EqualizedOdds,\n",
       " fairlearn.reductions._moments.utility_parity.TruePositiveRateParity,\n",
       " fairlearn.reductions._moments.utility_parity.FalsePositiveRateParity,\n",
       " fairlearn.reductions._moments.utility_parity.ErrorRateParity,\n",
       " fairlearn.reductions._moments.bounded_group_loss.BoundedGroupLoss)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DemographicParity, EqualizedOdds, \\\n",
    "    TruePositiveRateParity, FalsePositiveRateParity, ErrorRateParity, BoundedGroupLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True Positive Rate Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exponentiated Gradient Reduction Alg is used here with  TPRP  as the fairness constraint.\n",
      "\n",
      "Evaluation of  TPRP -constrained classifier overall:\n",
      "[[ 591  258]\n",
      " [ 136 2015]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.70      0.75       849\n",
      "           1       0.89      0.94      0.91      2151\n",
      "\n",
      "    accuracy                           0.87      3000\n",
      "   macro avg       0.85      0.82      0.83      3000\n",
      "weighted avg       0.87      0.87      0.87      3000\n",
      "\n",
      "FNER 0.06322640632264064\n",
      "FPER 0.303886925795053\n",
      "TNR 0.696113074204947\n",
      "TPR 0.9367735936773594\n",
      "\n",
      "\n",
      "Evaluation of  TPRP -constrained classifier by race:\n",
      "EVALUATION FOR BLACK GROUP\n",
      "[[114 119]\n",
      " [  5 121]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.49      0.65       233\n",
      "           1       0.50      0.96      0.66       126\n",
      "\n",
      "    accuracy                           0.65       359\n",
      "   macro avg       0.73      0.72      0.65       359\n",
      "weighted avg       0.80      0.65      0.65       359\n",
      "\n",
      "FNER 0.03968253968253968\n",
      "FPER 0.5107296137339056\n",
      "TNR 0.4892703862660944\n",
      "TPR 0.9603174603174603\n",
      "\n",
      "EVALUATION FOR WHITE GROUP\n",
      "[[ 477  139]\n",
      " [ 131 1894]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.78       616\n",
      "           1       0.93      0.94      0.93      2025\n",
      "\n",
      "    accuracy                           0.90      2641\n",
      "   macro avg       0.86      0.85      0.86      2641\n",
      "weighted avg       0.90      0.90      0.90      2641\n",
      "\n",
      "FNER 0.06469135802469136\n",
      "FPER 0.22564935064935066\n",
      "TNR 0.7743506493506493\n",
      "TPR 0.9353086419753086\n",
      "\n",
      "\n",
      "Fairness metric evaluation of  TPRP -constrained classifier\n",
      "Selection Rate Overall:  0.7576666666666667\n",
      "Selection Rate By Group:  sensitive_feature_0\n",
      "0    0.668524\n",
      "1    0.769784\n",
      "Name: selection_rate, dtype: object \n",
      "\n",
      "Note: difference of 0 means that all groups have the same selection rate.\n",
      "DP Difference:  0.10126049578164764\n",
      "Note: ratio of 1 means that all groups have the same selection rate.\n",
      "DP Ratio: 0.8684559914612241 \n",
      "\n",
      "Note: difference of 0 means that all groups have the same TN, TN, FP, and FN rates.\n",
      "EOD Difference:  0.2850802630845549\n",
      "Note: ratio of 1 means that all groups have the same TN, TN, FP, and FN rates rates.\n",
      "EOD Ratio: 0.44181763614536723 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_contraint('TPRP', 'EG', X_train, y_train, race_train, X_test, y_test, sample_weight_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Positive Rate Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exponentiated Gradient Reduction Alg is used here with  FPRP  as the fairness constraint.\n",
      "\n",
      "Evaluation of  FPRP -constrained classifier overall:\n",
      "[[ 663  186]\n",
      " [ 559 1592]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.78      0.64       849\n",
      "           1       0.90      0.74      0.81      2151\n",
      "\n",
      "    accuracy                           0.75      3000\n",
      "   macro avg       0.72      0.76      0.73      3000\n",
      "weighted avg       0.80      0.75      0.76      3000\n",
      "\n",
      "FNER 0.2598791259879126\n",
      "FPER 0.21908127208480566\n",
      "TNR 0.7809187279151943\n",
      "TPR 0.7401208740120874\n",
      "\n",
      "\n",
      "Evaluation of  FPRP -constrained classifier by race:\n",
      "EVALUATION FOR BLACK GROUP\n",
      "[[187  46]\n",
      " [ 73  53]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.80      0.76       233\n",
      "           1       0.54      0.42      0.47       126\n",
      "\n",
      "    accuracy                           0.67       359\n",
      "   macro avg       0.63      0.61      0.61       359\n",
      "weighted avg       0.65      0.67      0.66       359\n",
      "\n",
      "FNER 0.5793650793650794\n",
      "FPER 0.19742489270386265\n",
      "TNR 0.8025751072961373\n",
      "TPR 0.42063492063492064\n",
      "\n",
      "EVALUATION FOR WHITE GROUP\n",
      "[[ 476  140]\n",
      " [ 486 1539]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.77      0.60       616\n",
      "           1       0.92      0.76      0.83      2025\n",
      "\n",
      "    accuracy                           0.76      2641\n",
      "   macro avg       0.71      0.77      0.72      2641\n",
      "weighted avg       0.82      0.76      0.78      2641\n",
      "\n",
      "FNER 0.24\n",
      "FPER 0.22727272727272727\n",
      "TNR 0.7727272727272727\n",
      "TPR 0.76\n",
      "\n",
      "\n",
      "Fairness metric evaluation of  FPRP -constrained classifier\n",
      "Selection Rate Overall:  0.5926666666666667\n",
      "Selection Rate By Group:  sensitive_feature_0\n",
      "0    0.275766\n",
      "1    0.635744\n",
      "Name: selection_rate, dtype: object \n",
      "\n",
      "Note: difference of 0 means that all groups have the same selection rate.\n",
      "DP Difference:  0.3599780196367755\n",
      "Note: ratio of 1 means that all groups have the same selection rate.\n",
      "DP Ratio: 0.43376893992809756 \n",
      "\n",
      "Note: difference of 0 means that all groups have the same TN, TN, FP, and FN rates.\n",
      "EOD Difference:  0.33936507936507937\n",
      "Note: ratio of 1 means that all groups have the same TN, TN, FP, and FN rates rates.\n",
      "EOD Ratio: 0.5534670008354219 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_contraint('FPRP', 'EG', X_train, y_train, race_train, X_test, y_test, sample_weight_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Rate Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exponentiated Gradient Reduction Alg is used here with  ERP  as the fairness constraint.\n",
      "\n",
      "Evaluation of  ERP -constrained classifier overall:\n",
      "[[ 618  231]\n",
      " [ 272 1879]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.73      0.71       849\n",
      "           1       0.89      0.87      0.88      2151\n",
      "\n",
      "    accuracy                           0.83      3000\n",
      "   macro avg       0.79      0.80      0.80      3000\n",
      "weighted avg       0.84      0.83      0.83      3000\n",
      "\n",
      "FNER 0.12645281264528127\n",
      "FPER 0.27208480565371024\n",
      "TNR 0.7279151943462897\n",
      "TPR 0.8735471873547187\n",
      "\n",
      "\n",
      "Evaluation of  ERP -constrained classifier by race:\n",
      "EVALUATION FOR BLACK GROUP\n",
      "[[221  12]\n",
      " [ 52  74]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87       233\n",
      "           1       0.86      0.59      0.70       126\n",
      "\n",
      "    accuracy                           0.82       359\n",
      "   macro avg       0.83      0.77      0.79       359\n",
      "weighted avg       0.83      0.82      0.81       359\n",
      "\n",
      "FNER 0.4126984126984127\n",
      "FPER 0.05150214592274678\n",
      "TNR 0.9484978540772532\n",
      "TPR 0.5873015873015873\n",
      "\n",
      "EVALUATION FOR WHITE GROUP\n",
      "[[ 397  219]\n",
      " [ 220 1805]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       616\n",
      "           1       0.89      0.89      0.89      2025\n",
      "\n",
      "    accuracy                           0.83      2641\n",
      "   macro avg       0.77      0.77      0.77      2641\n",
      "weighted avg       0.83      0.83      0.83      2641\n",
      "\n",
      "FNER 0.10864197530864197\n",
      "FPER 0.3555194805194805\n",
      "TNR 0.6444805194805194\n",
      "TPR 0.891358024691358\n",
      "\n",
      "\n",
      "Fairness metric evaluation of  ERP -constrained classifier\n",
      "Selection Rate Overall:  0.7033333333333334\n",
      "Selection Rate By Group:  sensitive_feature_0\n",
      "0    0.239554\n",
      "1    0.766376\n",
      "Name: selection_rate, dtype: object \n",
      "\n",
      "Note: difference of 0 means that all groups have the same selection rate.\n",
      "DP Difference:  0.5268220550373952\n",
      "Note: ratio of 1 means that all groups have the same selection rate.\n",
      "DP Ratio: 0.3125805102007112 \n",
      "\n",
      "Note: difference of 0 means that all groups have the same TN, TN, FP, and FN rates.\n",
      "EOD Difference:  0.30405643738977073\n",
      "Note: ratio of 1 means that all groups have the same TN, TN, FP, and FN rates rates.\n",
      "EOD Ratio: 0.14486448350873068 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_contraint('ERP', 'EG', X_train, y_train, race_train, X_test, y_test, sample_weight_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bounded Group Loss (TODO: issue, need to figure out loss parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_contraint('BGL', 'EG', X_train, y_train, race_train, X_test, y_test, sample_weight_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Reduction Alg for Adding Fairness Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographic Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search Reduction Alg is used here with  DP  as the fairness constraint.\n",
      "\n",
      "Evaluation of  DP -constrained classifier overall:\n",
      "[[ 552  297]\n",
      " [ 122 2029]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.65      0.72       849\n",
      "           1       0.87      0.94      0.91      2151\n",
      "\n",
      "    accuracy                           0.86      3000\n",
      "   macro avg       0.85      0.80      0.82      3000\n",
      "weighted avg       0.86      0.86      0.86      3000\n",
      "\n",
      "FNER 0.056717805671780565\n",
      "FPER 0.3498233215547703\n",
      "TNR 0.6501766784452296\n",
      "TPR 0.9432821943282195\n",
      "\n",
      "\n",
      "Evaluation of  DP -constrained classifier by race:\n",
      "EVALUATION FOR BLACK GROUP\n",
      "[[ 82 151]\n",
      " [  1 125]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.35      0.52       233\n",
      "           1       0.45      0.99      0.62       126\n",
      "\n",
      "    accuracy                           0.58       359\n",
      "   macro avg       0.72      0.67      0.57       359\n",
      "weighted avg       0.80      0.58      0.56       359\n",
      "\n",
      "FNER 0.007936507936507936\n",
      "FPER 0.648068669527897\n",
      "TNR 0.351931330472103\n",
      "TPR 0.9920634920634921\n",
      "\n",
      "EVALUATION FOR WHITE GROUP\n",
      "[[ 470  146]\n",
      " [ 121 1904]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.76      0.78       616\n",
      "           1       0.93      0.94      0.93      2025\n",
      "\n",
      "    accuracy                           0.90      2641\n",
      "   macro avg       0.86      0.85      0.86      2641\n",
      "weighted avg       0.90      0.90      0.90      2641\n",
      "\n",
      "FNER 0.05975308641975308\n",
      "FPER 0.237012987012987\n",
      "TNR 0.762987012987013\n",
      "TPR 0.9402469135802469\n",
      "\n",
      "\n",
      "Fairness metric evaluation of  DP -constrained classifier\n",
      "Selection Rate Overall:  0.7753333333333333\n",
      "Selection Rate By Group:  sensitive_feature_0\n",
      "0    0.768802\n",
      "1    0.776221\n",
      "Name: selection_rate, dtype: object \n",
      "\n",
      "Note: difference of 0 means that all groups have the same selection rate.\n",
      "DP Difference:  0.007418899948213209\n",
      "Note: ratio of 1 means that all groups have the same selection rate.\n",
      "DP Ratio: 0.9904422854813507 \n",
      "\n",
      "Note: difference of 0 means that all groups have the same TN, TN, FP, and FN rates.\n",
      "EOD Difference:  0.41105568251491\n",
      "Note: ratio of 1 means that all groups have the same TN, TN, FP, and FN rates rates.\n",
      "EOD Ratio: 0.3657220263180528 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_contraint('DP', 'GS', X_train, y_train, race_train, X_test, y_test, sample_weight_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equalized Odds Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search Reduction Alg is used here with  EO  as the fairness constraint.\n",
      "\n",
      "Evaluation of  EO -constrained classifier overall:\n",
      "[[ 620  229]\n",
      " [ 112 2039]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.73      0.78       849\n",
      "           1       0.90      0.95      0.92      2151\n",
      "\n",
      "    accuracy                           0.89      3000\n",
      "   macro avg       0.87      0.84      0.85      3000\n",
      "weighted avg       0.88      0.89      0.88      3000\n",
      "\n",
      "FNER 0.05206880520688052\n",
      "FPER 0.2697290930506478\n",
      "TNR 0.7302709069493521\n",
      "TPR 0.9479311947931195\n",
      "\n",
      "\n",
      "Evaluation of  EO -constrained classifier by race:\n",
      "EVALUATION FOR BLACK GROUP\n",
      "[[209  24]\n",
      " [ 30  96]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89       233\n",
      "           1       0.80      0.76      0.78       126\n",
      "\n",
      "    accuracy                           0.85       359\n",
      "   macro avg       0.84      0.83      0.83       359\n",
      "weighted avg       0.85      0.85      0.85       359\n",
      "\n",
      "FNER 0.23809523809523808\n",
      "FPER 0.10300429184549356\n",
      "TNR 0.8969957081545065\n",
      "TPR 0.7619047619047619\n",
      "\n",
      "EVALUATION FOR WHITE GROUP\n",
      "[[ 411  205]\n",
      " [  82 1943]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.67      0.74       616\n",
      "           1       0.90      0.96      0.93      2025\n",
      "\n",
      "    accuracy                           0.89      2641\n",
      "   macro avg       0.87      0.81      0.84      2641\n",
      "weighted avg       0.89      0.89      0.89      2641\n",
      "\n",
      "FNER 0.04049382716049383\n",
      "FPER 0.3327922077922078\n",
      "TNR 0.6672077922077922\n",
      "TPR 0.9595061728395061\n",
      "\n",
      "\n",
      "Fairness metric evaluation of  EO -constrained classifier\n",
      "Selection Rate Overall:  0.756\n",
      "Selection Rate By Group:  sensitive_feature_0\n",
      "0    0.334262\n",
      "1    0.813328\n",
      "Name: selection_rate, dtype: object \n",
      "\n",
      "Note: difference of 0 means that all groups have the same selection rate.\n",
      "DP Difference:  0.47906644630051715\n",
      "Note: ratio of 1 means that all groups have the same selection rate.\n",
      "DP Ratio: 0.41098022128507183 \n",
      "\n",
      "Note: difference of 0 means that all groups have the same TN, TN, FP, and FN rates.\n",
      "EOD Difference:  0.22978791594671424\n",
      "Note: ratio of 1 means that all groups have the same TN, TN, FP, and FN rates rates.\n",
      "EOD Ratio: 0.30951533549670257 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_contraint('EO', 'GS', X_train, y_train, race_train, X_test, y_test, sample_weight_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True Positive Rate Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search Reduction Alg is used here with  TPRP  as the fairness constraint.\n",
      "\n",
      "Evaluation of  TPRP -constrained classifier overall:\n",
      "[[ 617  232]\n",
      " [ 116 2035]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.73      0.78       849\n",
      "           1       0.90      0.95      0.92      2151\n",
      "\n",
      "    accuracy                           0.88      3000\n",
      "   macro avg       0.87      0.84      0.85      3000\n",
      "weighted avg       0.88      0.88      0.88      3000\n",
      "\n",
      "FNER 0.05392840539284054\n",
      "FPER 0.27326266195524146\n",
      "TNR 0.7267373380447585\n",
      "TPR 0.9460715946071595\n",
      "\n",
      "\n",
      "Evaluation of  TPRP -constrained classifier by race:\n",
      "EVALUATION FOR BLACK GROUP\n",
      "[[213  20]\n",
      " [ 39  87]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       233\n",
      "           1       0.81      0.69      0.75       126\n",
      "\n",
      "    accuracy                           0.84       359\n",
      "   macro avg       0.83      0.80      0.81       359\n",
      "weighted avg       0.83      0.84      0.83       359\n",
      "\n",
      "FNER 0.30952380952380953\n",
      "FPER 0.08583690987124463\n",
      "TNR 0.9141630901287554\n",
      "TPR 0.6904761904761905\n",
      "\n",
      "EVALUATION FOR WHITE GROUP\n",
      "[[ 404  212]\n",
      " [  77 1948]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.66      0.74       616\n",
      "           1       0.90      0.96      0.93      2025\n",
      "\n",
      "    accuracy                           0.89      2641\n",
      "   macro avg       0.87      0.81      0.83      2641\n",
      "weighted avg       0.89      0.89      0.89      2641\n",
      "\n",
      "FNER 0.03802469135802469\n",
      "FPER 0.34415584415584416\n",
      "TNR 0.6558441558441559\n",
      "TPR 0.9619753086419753\n",
      "\n",
      "\n",
      "Fairness metric evaluation of  TPRP -constrained classifier\n",
      "Selection Rate Overall:  0.7556666666666667\n",
      "Selection Rate By Group:  sensitive_feature_0\n",
      "0     0.29805\n",
      "1    0.817872\n",
      "Name: selection_rate, dtype: object \n",
      "\n",
      "Note: difference of 0 means that all groups have the same selection rate.\n",
      "DP Difference:  0.5198218788991678\n",
      "Note: ratio of 1 means that all groups have the same selection rate.\n",
      "DP Ratio: 0.3644214897348602 \n",
      "\n",
      "Note: difference of 0 means that all groups have the same TN, TN, FP, and FN rates.\n",
      "EOD Difference:  0.27149911816578487\n",
      "Note: ratio of 1 means that all groups have the same TN, TN, FP, and FN rates rates.\n",
      "EOD Ratio: 0.24941290792776744 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_contraint('TPRP', 'GS', X_train, y_train, race_train, X_test, y_test, sample_weight_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Positive Rate Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search Reduction Alg is used here with  FPRP  as the fairness constraint.\n",
      "\n",
      "Evaluation of  FPRP -constrained classifier overall:\n",
      "[[ 617  232]\n",
      " [ 188 1963]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       849\n",
      "           1       0.89      0.91      0.90      2151\n",
      "\n",
      "    accuracy                           0.86      3000\n",
      "   macro avg       0.83      0.82      0.82      3000\n",
      "weighted avg       0.86      0.86      0.86      3000\n",
      "\n",
      "FNER 0.08740120874012088\n",
      "FPER 0.27326266195524146\n",
      "TNR 0.7267373380447585\n",
      "TPR 0.9125987912598791\n",
      "\n",
      "\n",
      "Evaluation of  FPRP -constrained classifier by race:\n",
      "EVALUATION FOR BLACK GROUP\n",
      "[[233   0]\n",
      " [122   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.79       233\n",
      "           1       1.00      0.03      0.06       126\n",
      "\n",
      "    accuracy                           0.66       359\n",
      "   macro avg       0.83      0.52      0.43       359\n",
      "weighted avg       0.78      0.66      0.54       359\n",
      "\n",
      "FNER 0.9682539682539683\n",
      "FPER 0.0\n",
      "TNR 1.0\n",
      "TPR 0.031746031746031744\n",
      "\n",
      "EVALUATION FOR WHITE GROUP\n",
      "[[ 384  232]\n",
      " [  66 1959]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.62      0.72       616\n",
      "           1       0.89      0.97      0.93      2025\n",
      "\n",
      "    accuracy                           0.89      2641\n",
      "   macro avg       0.87      0.80      0.82      2641\n",
      "weighted avg       0.88      0.89      0.88      2641\n",
      "\n",
      "FNER 0.03259259259259259\n",
      "FPER 0.37662337662337664\n",
      "TNR 0.6233766233766234\n",
      "TPR 0.9674074074074074\n",
      "\n",
      "\n",
      "Fairness metric evaluation of  FPRP -constrained classifier\n",
      "Selection Rate Overall:  0.7316666666666667\n",
      "Selection Rate By Group:  sensitive_feature_0\n",
      "0    0.0111421\n",
      "1      0.82961\n",
      "Name: selection_rate, dtype: object \n",
      "\n",
      "Note: difference of 0 means that all groups have the same selection rate.\n",
      "DP Difference:  0.8184679349322184\n",
      "Note: ratio of 1 means that all groups have the same selection rate.\n",
      "DP Ratio: 0.013430480987681945 \n",
      "\n",
      "Note: difference of 0 means that all groups have the same TN, TN, FP, and FN rates.\n",
      "EOD Difference:  0.9356613756613756\n",
      "Note: ratio of 1 means that all groups have the same TN, TN, FP, and FN rates rates.\n",
      "EOD Ratio: 0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_contraint('FPRP', 'GS', X_train, y_train, race_train, X_test, y_test, sample_weight_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Rate Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search Reduction Alg is used here with  ERP  as the fairness constraint.\n",
      "\n",
      "Evaluation of  ERP -constrained classifier overall:\n",
      "[[ 607  242]\n",
      " [ 122 2029]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.77       849\n",
      "           1       0.89      0.94      0.92      2151\n",
      "\n",
      "    accuracy                           0.88      3000\n",
      "   macro avg       0.86      0.83      0.84      3000\n",
      "weighted avg       0.88      0.88      0.88      3000\n",
      "\n",
      "FNER 0.056717805671780565\n",
      "FPER 0.2850412249705536\n",
      "TNR 0.7149587750294464\n",
      "TPR 0.9432821943282195\n",
      "\n",
      "\n",
      "Evaluation of  ERP -constrained classifier by race:\n",
      "EVALUATION FOR BLACK GROUP\n",
      "[[223  10]\n",
      " [ 56  70]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87       233\n",
      "           1       0.88      0.56      0.68       126\n",
      "\n",
      "    accuracy                           0.82       359\n",
      "   macro avg       0.84      0.76      0.78       359\n",
      "weighted avg       0.83      0.82      0.80       359\n",
      "\n",
      "FNER 0.4444444444444444\n",
      "FPER 0.04291845493562232\n",
      "TNR 0.9570815450643777\n",
      "TPR 0.5555555555555556\n",
      "\n",
      "EVALUATION FOR WHITE GROUP\n",
      "[[ 384  232]\n",
      " [  66 1959]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.62      0.72       616\n",
      "           1       0.89      0.97      0.93      2025\n",
      "\n",
      "    accuracy                           0.89      2641\n",
      "   macro avg       0.87      0.80      0.82      2641\n",
      "weighted avg       0.88      0.89      0.88      2641\n",
      "\n",
      "FNER 0.03259259259259259\n",
      "FPER 0.37662337662337664\n",
      "TNR 0.6233766233766234\n",
      "TPR 0.9674074074074074\n",
      "\n",
      "\n",
      "Fairness metric evaluation of  ERP -constrained classifier\n",
      "Selection Rate Overall:  0.757\n",
      "Selection Rate By Group:  sensitive_feature_0\n",
      "0    0.222841\n",
      "1     0.82961\n",
      "Name: selection_rate, dtype: object \n",
      "\n",
      "Note: difference of 0 means that all groups have the same selection rate.\n",
      "DP Difference:  0.6067687705868146\n",
      "Note: ratio of 1 means that all groups have the same selection rate.\n",
      "DP Ratio: 0.2686096197536389 \n",
      "\n",
      "Note: difference of 0 means that all groups have the same TN, TN, FP, and FN rates.\n",
      "EOD Difference:  0.4118518518518518\n",
      "Note: ratio of 1 means that all groups have the same TN, TN, FP, and FN rates rates.\n",
      "EOD Ratio: 0.11395589758768684 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_contraint('ERP', 'GS', X_train, y_train, race_train, X_test, y_test, sample_weight_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bounded Group Loss (TODO: issue, need to figure out loss parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_contraint('BGL', 'GS', X_train, y_train, race_train, X_test, y_test, sample_weight_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: USE BELOW CHUNK TO TEST FAIRLEARN DASHBOARD??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Reduction Algorithm to make the classifier DP-constrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference for this cell's code: https://fairlearn.org/main/quickstart.html\n",
    "# Reduction Algs explained here: https://fairlearn.org/main/user_guide/mitigation.html#reductions\n",
    "\n",
    "# TODO--try Gridsearch reduction alg: https://fairlearn.org/main/user_guide/mitigation.html\n",
    "\n",
    "# set seed for consistent results with ExponentiatedGradient\n",
    "np.random.seed(0)  \n",
    "constraint = DemographicParity()\n",
    "mitigator = ExponentiatedGradient(model, constraint)\n",
    "mitigator.fit(X_train, y_train, sensitive_features=race_train)\n",
    "y_pred_mitigated = mitigator.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of DP-constrained classifier overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 615  234]\n",
      " [ 909 1242]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.72      0.52       849\n",
      "           1       0.84      0.58      0.68      2151\n",
      "\n",
      "    accuracy                           0.62      3000\n",
      "   macro avg       0.62      0.65      0.60      3000\n",
      "weighted avg       0.72      0.62      0.64      3000\n",
      "\n",
      "FNER 0.4225941422594142\n",
      "FPER 0.2756183745583039\n",
      "TNR 0.7243816254416962\n",
      "TPR 0.5774058577405857\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_mitigated))\n",
    "print(classification_report(y_test, y_pred_mitigated)) \n",
    "evaluation_outcome_rates(y_test, y_pred_mitigated, sample_weight_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of DP-constrained classifier by race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION FOR BLACK GROUP\n",
      "[[114 119]\n",
      " [ 72  54]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.49      0.54       233\n",
      "           1       0.31      0.43      0.36       126\n",
      "\n",
      "    accuracy                           0.47       359\n",
      "   macro avg       0.46      0.46      0.45       359\n",
      "weighted avg       0.51      0.47      0.48       359\n",
      "\n",
      "FNER 0.5714285714285714\n",
      "FPER 0.5107296137339056\n",
      "TNR 0.4892703862660944\n",
      "TPR 0.42857142857142855\n",
      "\n",
      "EVALUATION FOR WHITE GROUP\n",
      "[[ 501  115]\n",
      " [ 837 1188]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.81      0.51       616\n",
      "           1       0.91      0.59      0.71      2025\n",
      "\n",
      "    accuracy                           0.64      2641\n",
      "   macro avg       0.64      0.70      0.61      2641\n",
      "weighted avg       0.79      0.64      0.67      2641\n",
      "\n",
      "FNER 0.41333333333333333\n",
      "FPER 0.18668831168831168\n",
      "TNR 0.8133116883116883\n",
      "TPR 0.5866666666666667\n"
     ]
    }
   ],
   "source": [
    "evaluation_by_race(X_test, y_test, y_pred_mitigated, sample_weight_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Metric Evaluation of DP-constrained classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection Rate Overall:  0.492\n",
      "Selection Rate By Group:  sensitive_feature_0\n",
      "0    0.481894\n",
      "1    0.493374\n",
      "Name: selection_rate, dtype: object \n",
      "\n",
      "Note: difference of 0 means that all groups have the same selection rate.\n",
      "DP Difference:  0.011479571657144305\n",
      "Note: ratio of 1 means that all groups have the same selection rate.\n",
      "DP Ratio: 0.9767325028806462 \n",
      "\n",
      "Note: difference of 0 means that all groups have the same TN, TN, FP, and FN rates.\n",
      "EOD Difference:  0.3240413020455939\n",
      "Note: ratio of 1 means that all groups have the same TN, TN, FP, and FN rates rates.\n",
      "EOD Ratio: 0.36553257666703043 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_fairness_metrics(y_true=y_test, y_pred=y_pred_mitigated, sensitive_features=race_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mackenzie/.local/lib/python3.8/site-packages/fairlearn/widget/_fairlearn_dashboard.py:47: UserWarning: The FairlearnDashboard will move from Fairlearn to the raiwidgets package after the v0.5.0 release. Instead, Fairlearn will provide some of the existing functionality through matplotlib-based visualizations.\n",
      "  warn(\"The FairlearnDashboard will move from Fairlearn to the \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc46e129455a461280ce45713d593a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FairlearnWidget(value={'true_y': [0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<fairlearn.widget._fairlearn_dashboard.FairlearnDashboard at 0x7f483df21c40>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: figure out how to get the widget to work, https://fairlearn.org/v0.6.2/api_reference/fairlearn.widget.html\n",
    "# Roman said that there was a new version out / try using raiwidgets\n",
    "# TODO: update fairlearn widget and try to get dashboard to go\n",
    "from fairlearn.widget import FairlearnDashboard\n",
    "FairlearnDashboard(sensitive_features=race_test,\n",
    "                   sensitive_feature_names=['race'],\n",
    "                   y_true=y_test,\n",
    "                   y_pred={\"initial model\": y_predict, \"mitigated model\": y_pred_mitigated}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System:\n",
      "    python: 3.8.10 (default, Jun  2 2021, 10:49:15)  [GCC 9.4.0]\n",
      "executable: /usr/bin/python3\n",
      "   machine: Linux-5.8.0-59-generic-x86_64-with-glibc2.29\n",
      "\n",
      "Python dependencies:\n",
      "    Cython: 0.29.21\n",
      "matplotlib: 3.3.3\n",
      "     numpy: 1.19.5\n",
      "    pandas: 1.1.5\n",
      "       pip: 20.0.2\n",
      "     scipy: 1.4.1\n",
      "setuptools: 45.2.0\n",
      "   sklearn: 0.24.1\n",
      "    tempeh: None\n"
     ]
    }
   ],
   "source": [
    "from fairlearn import show_versions\n",
    "show_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: fairlearn\n",
      "Version: 0.6.2\n",
      "Summary: Algorithms for mitigating unfairness in supervised machine learning\n",
      "Home-page: https://github.com/fairlearn/fairlearn\n",
      "Author: Miroslav Dudik, Richard Edgar, Brandon Horn, Roman Lutz\n",
      "Author-email: fairlearn@microsoft.com\n",
      "License: UNKNOWN\n",
      "Location: /home/mackenzie/.local/lib/python3.8/site-packages\n",
      "Requires: numpy, pandas, scikit-learn, scipy\n",
      "Required-by: parity-fairness\n",
      "---\n",
      "Name: jupyter\n",
      "Version: 1.0.0\n",
      "Summary: Jupyter metapackage. Install all the Jupyter components in one go.\n",
      "Home-page: http://jupyter.org\n",
      "Author: Jupyter Development Team\n",
      "Author-email: jupyter@googlegroups.org\n",
      "License: BSD\n",
      "Location: /home/mackenzie/.local/lib/python3.8/site-packages\n",
      "Requires: ipywidgets, notebook, ipykernel, qtconsole, jupyter-console, nbconvert\n",
      "Required-by: witwidget\n",
      "---\n",
      "Name: notebook\n",
      "Version: 6.4.0\n",
      "Summary: A web-based notebook environment for interactive computing\n",
      "Home-page: http://jupyter.org\n",
      "Author: Jupyter Development Team\n",
      "Author-email: jupyter@googlegroups.com\n",
      "License: BSD\n",
      "Location: /home/mackenzie/.local/lib/python3.8/site-packages\n",
      "Requires: jinja2, jupyter-client, tornado, argon2-cffi, jupyter-core, Send2Trash, nbformat, ipykernel, nbconvert, pyzmq, ipython-genutils, prometheus-client, terminado, traitlets\n",
      "Required-by: widgetsnbextension, jupyter, jupyter-http-over-ws\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show fairlearn jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier with Fairlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add cells from above!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://www.datacamp.com/community/tutorials/decision-tree-classification-python\n",
    "\n",
    "# Initialize classifier:\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train the classifier:\n",
    "clf = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 617  232]\n",
      " [ 188 1963]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       849\n",
      "           1       0.89      0.91      0.90      2151\n",
      "\n",
      "    accuracy                           0.86      3000\n",
      "   macro avg       0.83      0.82      0.82      3000\n",
      "weighted avg       0.86      0.86      0.86      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with the classifier:\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(classification_report(y_test, y_predict)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION FOR BLACK GROUP\n",
      "[[233   0]\n",
      " [122   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.79       233\n",
      "           1       1.00      0.03      0.06       126\n",
      "\n",
      "    accuracy                           0.66       359\n",
      "   macro avg       0.83      0.52      0.43       359\n",
      "weighted avg       0.78      0.66      0.54       359\n",
      "\n",
      "EVALUATION FOR WHITE GROUP\n",
      "[[ 384  232]\n",
      " [  66 1959]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.62      0.72       616\n",
      "           1       0.89      0.97      0.93      2025\n",
      "\n",
      "    accuracy                           0.89      2641\n",
      "   macro avg       0.87      0.80      0.82      2641\n",
      "weighted avg       0.88      0.89      0.88      2641\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation_by_race(X_test, y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with Fairlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add cells from above!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reference: https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a\n",
    "\n",
    "# Instantiate classifier:\n",
    "logisticRegr = LogisticRegression()\n",
    "\n",
    "# Train the classifier:\n",
    "logisticRegr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 617  232]\n",
      " [ 188 1963]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       849\n",
      "           1       0.89      0.91      0.90      2151\n",
      "\n",
      "    accuracy                           0.86      3000\n",
      "   macro avg       0.83      0.82      0.82      3000\n",
      "weighted avg       0.86      0.86      0.86      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with the classifier:\n",
    "y_pred = logisticRegr.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(classification_report(y_test, y_predict)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION FOR BLACK GROUP\n",
      "[[233   0]\n",
      " [122   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.79       233\n",
      "           1       1.00      0.03      0.06       126\n",
      "\n",
      "    accuracy                           0.66       359\n",
      "   macro avg       0.83      0.52      0.43       359\n",
      "weighted avg       0.78      0.66      0.54       359\n",
      "\n",
      "EVALUATION FOR WHITE GROUP\n",
      "[[ 384  232]\n",
      " [  66 1959]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.62      0.72       616\n",
      "           1       0.89      0.97      0.93      2025\n",
      "\n",
      "    accuracy                           0.89      2641\n",
      "   macro avg       0.87      0.80      0.82      2641\n",
      "weighted avg       0.88      0.89      0.88      2641\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation_by_race(X_test, y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines with Fairlearn\n",
    "\n",
    "Reference: https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add cells from above!!\n",
    "# TODO: try other svm kernels??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate classifier:\n",
    "clf = svm.SVC(kernel='linear')  # can try other kernels\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 617  232]\n",
      " [ 188 1963]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       849\n",
      "           1       0.89      0.91      0.90      2151\n",
      "\n",
      "    accuracy                           0.86      3000\n",
      "   macro avg       0.83      0.82      0.82      3000\n",
      "weighted avg       0.86      0.86      0.86      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION FOR BLACK GROUP\n",
      "[[233   0]\n",
      " [122   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.79       233\n",
      "           1       1.00      0.03      0.06       126\n",
      "\n",
      "    accuracy                           0.66       359\n",
      "   macro avg       0.83      0.52      0.43       359\n",
      "weighted avg       0.78      0.66      0.54       359\n",
      "\n",
      "EVALUATION FOR WHITE GROUP\n",
      "[[ 384  232]\n",
      " [  66 1959]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.62      0.72       616\n",
      "           1       0.89      0.97      0.93      2025\n",
      "\n",
      "    accuracy                           0.89      2641\n",
      "   macro avg       0.87      0.80      0.82      2641\n",
      "weighted avg       0.88      0.89      0.88      2641\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation_by_race(X_test, y_test, y_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
