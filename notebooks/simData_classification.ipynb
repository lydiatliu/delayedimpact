{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_by_race(X_test, y_test, y_predict):\n",
    "    races_test = X_test[:, 1]\n",
    "    \n",
    "    y_test_black = []\n",
    "    y_pred_black = []\n",
    "    y_test_white = []\n",
    "    y_pred_white = []\n",
    "\n",
    "    # splitting up the y_test and y_pred values by race to then use for race specific classification reports\n",
    "    for index, race in enumerate(races_test):\n",
    "        if(race == 0):  # black\n",
    "            y_test_black.append(y_test[index])\n",
    "            y_pred_black.append(y_predict[index])\n",
    "        elif(race == 1):  # white\n",
    "            y_test_white.append(y_test[index])\n",
    "            y_pred_white.append(y_predict[index])\n",
    "        else:\n",
    "            print('You should not end up here...')\n",
    "            \n",
    "    print('EVALUATION FOR BLACK GROUP')\n",
    "    print(confusion_matrix(y_test_black, y_pred_black))\n",
    "    print(classification_report(y_test_black, y_pred_black)) \n",
    "    \n",
    "    print('EVALUATION FOR WHITE GROUP')\n",
    "    print(confusion_matrix(y_test_white, y_pred_white))\n",
    "    print(classification_report(y_test_white, y_pred_white)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Extract data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      score  repay_probability  race  repay_indices\n",
      "0       610              78.90     1              1\n",
      "1       568              47.77     0              0\n",
      "2       750              98.13     1              1\n",
      "3       775              98.45     1              1\n",
      "4       704              95.88     1              1\n",
      "...     ...                ...   ...            ...\n",
      "9995    832              98.99     1              1\n",
      "9996    416              10.91     1              0\n",
      "9997    444              14.63     1              0\n",
      "9998    778              98.47     1              1\n",
      "9999    738              97.68     1              1\n",
      "\n",
      "[10000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/home/mackenzie/git_repositories/delayedimpact/data/simData_oom10.csv')\n",
    "data[['score', 'race']] = data[['score', 'race']].astype(int)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Make data into train/test form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[['score', 'race']].values\n",
    "y = data['repay_indices'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# do I need to scale the data??\n",
    "# Standardize features by removing mean and scaling to unit variance:\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(X_train)\n",
    "\n",
    "#X_train = scaler.transform(X_train)\n",
    "#X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train+Test KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ref: https://www.activestate.com/resources/quick-reads/how-to-classify-data-in-python/\n",
    "\n",
    "# Use the KNN classifier to fit data:\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 634  215]\n",
      " [ 144 2007]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78       849\n",
      "           1       0.90      0.93      0.92      2151\n",
      "\n",
      "    accuracy                           0.88      3000\n",
      "   macro avg       0.86      0.84      0.85      3000\n",
      "weighted avg       0.88      0.88      0.88      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict y data with classifier: \n",
    "y_predict = classifier.predict(X_test)\n",
    "\n",
    "# Print results: \n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(classification_report(y_test, y_predict)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION FOR BLACK GROUP\n",
      "[[198  35]\n",
      " [ 30  96]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86       233\n",
      "           1       0.73      0.76      0.75       126\n",
      "\n",
      "    accuracy                           0.82       359\n",
      "   macro avg       0.80      0.81      0.80       359\n",
      "weighted avg       0.82      0.82      0.82       359\n",
      "\n",
      "EVALUATION FOR WHITE GROUP\n",
      "[[ 436  180]\n",
      " [ 114 1911]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.71      0.75       616\n",
      "           1       0.91      0.94      0.93      2025\n",
      "\n",
      "    accuracy                           0.89      2641\n",
      "   macro avg       0.85      0.83      0.84      2641\n",
      "weighted avg       0.89      0.89      0.89      2641\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation_by_race(X_test, y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train+Test Gaussian Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classifier:\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train the classifier:\n",
    "model = gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 617  232]\n",
      " [ 188 1963]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       849\n",
      "           1       0.89      0.91      0.90      2151\n",
      "\n",
      "    accuracy                           0.86      3000\n",
      "   macro avg       0.83      0.82      0.82      3000\n",
      "weighted avg       0.86      0.86      0.86      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with the classifier:\n",
    "y_predict = gnb.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(classification_report(y_test, y_predict)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION FOR BLACK GROUP\n",
      "[[233   0]\n",
      " [122   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.79       233\n",
      "           1       1.00      0.03      0.06       126\n",
      "\n",
      "    accuracy                           0.66       359\n",
      "   macro avg       0.83      0.52      0.43       359\n",
      "weighted avg       0.78      0.66      0.54       359\n",
      "\n",
      "EVALUATION FOR WHITE GROUP\n",
      "[[ 384  232]\n",
      " [  66 1959]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.62      0.72       616\n",
      "           1       0.89      0.97      0.93      2025\n",
      "\n",
      "    accuracy                           0.89      2641\n",
      "   macro avg       0.87      0.80      0.82      2641\n",
      "weighted avg       0.88      0.89      0.88      2641\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation_by_race(X_test, y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Train+Test Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://www.datacamp.com/community/tutorials/decision-tree-classification-python\n",
    "\n",
    "# Initialize classifier:\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train the classifier:\n",
    "clf = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 617  232]\n",
      " [ 188 1963]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       849\n",
      "           1       0.89      0.91      0.90      2151\n",
      "\n",
      "    accuracy                           0.86      3000\n",
      "   macro avg       0.83      0.82      0.82      3000\n",
      "weighted avg       0.86      0.86      0.86      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with the classifier:\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(classification_report(y_test, y_predict)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION FOR BLACK GROUP\n",
      "[[233   0]\n",
      " [122   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.79       233\n",
      "           1       1.00      0.03      0.06       126\n",
      "\n",
      "    accuracy                           0.66       359\n",
      "   macro avg       0.83      0.52      0.43       359\n",
      "weighted avg       0.78      0.66      0.54       359\n",
      "\n",
      "EVALUATION FOR WHITE GROUP\n",
      "[[ 384  232]\n",
      " [  66 1959]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.62      0.72       616\n",
      "           1       0.89      0.97      0.93      2025\n",
      "\n",
      "    accuracy                           0.89      2641\n",
      "   macro avg       0.87      0.80      0.82      2641\n",
      "weighted avg       0.88      0.89      0.88      2641\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation_by_race(X_test, y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Train+Test Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reference: https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a\n",
    "\n",
    "# Instantiate classifier:\n",
    "logisticRegr = LogisticRegression()\n",
    "\n",
    "# Train the classifier:\n",
    "logisticRegr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 617  232]\n",
      " [ 188 1963]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       849\n",
      "           1       0.89      0.91      0.90      2151\n",
      "\n",
      "    accuracy                           0.86      3000\n",
      "   macro avg       0.83      0.82      0.82      3000\n",
      "weighted avg       0.86      0.86      0.86      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with the classifier:\n",
    "y_pred = logisticRegr.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(classification_report(y_test, y_predict)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION FOR BLACK GROUP\n",
      "[[233   0]\n",
      " [122   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.79       233\n",
      "           1       1.00      0.03      0.06       126\n",
      "\n",
      "    accuracy                           0.66       359\n",
      "   macro avg       0.83      0.52      0.43       359\n",
      "weighted avg       0.78      0.66      0.54       359\n",
      "\n",
      "EVALUATION FOR WHITE GROUP\n",
      "[[ 384  232]\n",
      " [  66 1959]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.62      0.72       616\n",
      "           1       0.89      0.97      0.93      2025\n",
      "\n",
      "    accuracy                           0.89      2641\n",
      "   macro avg       0.87      0.80      0.82      2641\n",
      "weighted avg       0.88      0.89      0.88      2641\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation_by_race(X_test, y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Train+Test Support Vector Machines\n",
    "\n",
    "Reference: https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate classifier:\n",
    "clf = svm.SVC(kernel='linear')  # can try other kernels\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 617  232]\n",
      " [ 188 1963]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       849\n",
      "           1       0.89      0.91      0.90      2151\n",
      "\n",
      "    accuracy                           0.86      3000\n",
      "   macro avg       0.83      0.82      0.82      3000\n",
      "weighted avg       0.86      0.86      0.86      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION FOR BLACK GROUP\n",
      "[[233   0]\n",
      " [122   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.79       233\n",
      "           1       1.00      0.03      0.06       126\n",
      "\n",
      "    accuracy                           0.66       359\n",
      "   macro avg       0.83      0.52      0.43       359\n",
      "weighted avg       0.78      0.66      0.54       359\n",
      "\n",
      "EVALUATION FOR WHITE GROUP\n",
      "[[ 384  232]\n",
      " [  66 1959]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.62      0.72       616\n",
      "           1       0.89      0.97      0.93      2025\n",
      "\n",
      "    accuracy                           0.89      2641\n",
      "   macro avg       0.87      0.80      0.82      2641\n",
      "weighted avg       0.88      0.89      0.88      2641\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation_by_race(X_test, y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Notes\n",
    "\n",
    "TODO: increase dataset oom even more\n",
    "TODO: try other svm kernels\n",
    "\n",
    "https://stackabuse.com/overview-of-classification-methods-in-python-with-scikit-learn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
